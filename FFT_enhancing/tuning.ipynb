{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "import librosa.display\n",
    "import scipy.fftpack as fftpack\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'E:/Queenless/archive/nuhive_processed/train'\n",
    "val_path = 'E:/Queenless/archive/nuhive_processed/val'\n",
    "test_path = 'E:/Queenless/archive/nuhive_processed/test'\n",
    "\n",
    "output_dir = 'E:/Queenless/fft_features'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis(signal_in, pre_emph=0.97):\n",
    "    \"\"\"\n",
    "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        pre_emph: Hệ số pre-emphasis, mặc định là 0.97\n",
    "        \n",
    "    Returns:\n",
    "        Tín hiệu sau khi áp dụng pre-emphasis\n",
    "    \"\"\"\n",
    "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
    "\n",
    "def framing(signal_in, sample_rate, frame_size=0.025, hop_length=256, overlap=0.6):\n",
    "    \"\"\"\n",
    "    Chia tín hiệu thành các frame với kích thước và bước nhảy xác định.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu frame_size > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu hop_length > 1)\n",
    "                    Nếu None, sẽ được tính dựa trên overlap\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame, mặc định là 0.6 (60%)\n",
    "                Chỉ được sử dụng khi hop_length là None\n",
    "        \n",
    "    Returns:\n",
    "        Mảng 2D chứa các frame\n",
    "    \"\"\"\n",
    "    # Xác định kích thước frame trong số mẫu\n",
    "    if frame_size <= 1:  # Nếu frame_size <= 1, xem như đơn vị là giây\n",
    "        frame_length = int(round(frame_size * sample_rate))\n",
    "    else:  # Ngược lại, xem như đơn vị là số mẫu\n",
    "        frame_length = int(frame_size)\n",
    "    \n",
    "    # Xác định hop_length (bước nhảy) trong số mẫu\n",
    "    if hop_length is None:\n",
    "        # Tính hop_length từ overlap\n",
    "        frame_step = int(frame_length * (1 - overlap))\n",
    "    elif hop_length <= 1:  # Nếu hop_length <= 1, xem như đơn vị là giây\n",
    "        frame_step = int(round(hop_length * sample_rate))\n",
    "    else:  # Ngược lại, xem như đơn vị là số mẫu\n",
    "        frame_step = int(hop_length)\n",
    "    \n",
    "    # Đảm bảo hop_length không quá nhỏ\n",
    "    frame_step = max(1, frame_step)\n",
    "    \n",
    "    signal_length = len(signal_in)\n",
    "    \n",
    "    # Tính số frame cần thiết\n",
    "    num_frames = int(np.ceil((signal_length - frame_length) / frame_step)) + 1\n",
    "    \n",
    "    # Đệm tín hiệu để đảm bảo có đủ mẫu cho tất cả các frame\n",
    "    pad_signal_length = (num_frames - 1) * frame_step + frame_length\n",
    "    pad_zeros = np.zeros(pad_signal_length - signal_length)\n",
    "    padded_signal = np.concatenate([signal_in, pad_zeros])\n",
    "    \n",
    "    # Tạo indices cho từng frame\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    \n",
    "    # Đảm bảo indices không vượt quá độ dài tín hiệu\n",
    "    indices = np.minimum(indices, len(padded_signal) - 1)\n",
    "    \n",
    "    # Trích xuất các frame từ tín hiệu\n",
    "    frames = padded_signal[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def windowing(frames, window_type='bartlett'):\n",
    "    \"\"\"\n",
    "    Áp dụng cửa sổ cho mỗi frame.\n",
    "    \n",
    "    Args:\n",
    "        frames: Mảng 2D chứa các frame\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        \n",
    "    Returns:\n",
    "        Các frame sau khi áp dụng cửa sổ\n",
    "    \"\"\"\n",
    "    frame_length = frames.shape[1]\n",
    "    \n",
    "    if window_type == 'hamming':\n",
    "        window = np.hamming(frame_length)\n",
    "    elif window_type == 'hanning':\n",
    "        window = np.hanning(frame_length)\n",
    "    elif window_type == 'blackman':\n",
    "        window = np.blackman(frame_length)\n",
    "    elif window_type == 'bartlett':\n",
    "        window = np.bartlett(frame_length)\n",
    "    else:\n",
    "        window = np.hamming(frame_length)  # Mặc định là hamming\n",
    "        \n",
    "    return frames * window\n",
    "\n",
    "def fft_frames(frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
    "    \n",
    "    Args:\n",
    "        frames: Mảng 2D chứa các frame\n",
    "        NFFT: Kích thước FFT (số điểm FFT)\n",
    "        \n",
    "    Returns:\n",
    "        Magnitude của FFT\n",
    "    \"\"\"\n",
    "    return np.absolute(np.fft.rfft(frames, NFFT))\n",
    "\n",
    "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, hop_length=256, \n",
    "                         overlap=0.6, NFFT=512, apply_log=True, window_type='bartlett',\n",
    "                         normalize=False):\n",
    "    \"\"\"\n",
    "    Tính toán đặc trưng FFT cho tín hiệu âm thanh:\n",
    "      - Pre-emphasis, Framing, Windowing.\n",
    "      - Tính FFT cho từng frame và lấy giá trị magnitude.\n",
    "      - Trung bình các frame để có vector đặc trưng ổn định.\n",
    "      \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu > 1). Nếu None, sẽ sử dụng overlap\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame (0-1)\n",
    "        NFFT: Số điểm FFT\n",
    "        apply_log: Áp dụng logarit cho đặc trưng\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng có kích thước (NFFT//2+1,)\n",
    "    \"\"\"\n",
    "    # Áp dụng pre-emphasis\n",
    "    emphasized_signal = pre_emphasis(signal_in)\n",
    "    \n",
    "    # Chia tín hiệu thành các frame\n",
    "    frames = framing(emphasized_signal, sample_rate, frame_size, hop_length, overlap)\n",
    "    \n",
    "    # Áp dụng cửa sổ\n",
    "    windowed_frames = windowing(frames, window_type)\n",
    "    \n",
    "    # Tính FFT\n",
    "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
    "    \n",
    "    # Trung bình theo các frame\n",
    "    fft_feature = np.mean(mag_frames, axis=0)\n",
    "    \n",
    "    # Áp dụng logarithm (nếu cần)\n",
    "    if apply_log:\n",
    "        fft_feature = np.log(fft_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
    "    \n",
    "    # Chuẩn hóa (nếu cần)\n",
    "    if normalize:\n",
    "        fft_feature = (fft_feature - np.mean(fft_feature)) / (np.std(fft_feature) + 1e-8)\n",
    "    \n",
    "    return fft_feature\n",
    "\n",
    "def load_fft_features_from_directory(directory, sample_rate=22050, NFFT=512, \n",
    "                                     frame_size=0.025, hop_length=256, overlap=0.6,\n",
    "                                     window_type='bartlett', output_dir=None, \n",
    "                                     dataset_type='train', normalize=False):\n",
    "    \"\"\"\n",
    "    Duyệt qua các file âm thanh trong thư mục và tính đặc trưng FFT cho mỗi file.\n",
    "    \n",
    "    Args:\n",
    "        directory: Thư mục chứa dữ liệu âm thanh\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        NFFT: Số điểm FFT\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu > 1). Nếu None, sẽ sử dụng overlap\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame (0-1)\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        output_dir: Thư mục đầu ra để lưu đặc trưng\n",
    "        dataset_type: Loại tập dữ liệu ('train', 'test', 'val')\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        features: Mảng đặc trưng\n",
    "        labels: Nhãn tương ứng\n",
    "    \"\"\"\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    hop_str = f\"{hop_length}\" if hop_length else f\"overlap{overlap}\"\n",
    "    features_file = os.path.join(output_dir, f'fft_features_{dataset_type}_bartlett_nfft{NFFT}_hop{hop_str}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'fft_labels_{dataset_type}_bartlett_nfft{NFFT}_hop{hop_str}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        \n",
    "        for label in ['bee', 'nobee', 'noqueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Warning: Path {path} does not exist. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            for file in os.listdir(path):\n",
    "                if not file.endswith(('.wav', '.mp3', '.flac', '.ogg')):\n",
    "                    continue\n",
    "                    \n",
    "                file_path = os.path.join(path, file)\n",
    "                try:\n",
    "                    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                    fft_feature = compute_fft_features(\n",
    "                        signal, sr, frame_size=frame_size, hop_length=hop_length, \n",
    "                        overlap=overlap, NFFT=NFFT, window_type=window_type,\n",
    "                        normalize=normalize\n",
    "                    )\n",
    "                    features.append(fft_feature)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        \n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"FFT extraction time: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Features shape: {features.shape}, Labels shape: {labels.shape}\")\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from .pkl files...\n",
      "Loading val data from .pkl files...\n",
      "Loading test data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "train_features_fft, train_labels_fft = load_fft_features_from_directory(train_path, sample_rate=22050, NFFT=2048, output_dir=output_dir, dataset_type='train')\n",
    "val_features_fft, val_labels_fft = load_fft_features_from_directory(val_path, sample_rate=22050, NFFT=2048, output_dir=output_dir, dataset_type='val')\n",
    "test_features_fft, test_labels_fft = load_fft_features_from_directory(test_path, sample_rate=22050, NFFT=2048, output_dir=output_dir, dataset_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_fft_scaled = scaler.fit_transform(train_features_fft)\n",
    "val_features_fft_scaled = scaler.transform(val_features_fft)\n",
    "test_features_fft_scaled = scaler.transform(test_features_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.03 seconds\n",
      "KNN (FFT features) - Validation Accuracy: 86.15%\n",
      "KNN (FFT features) - Test Accuracy: 86.16%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_knn = knn_classifier.predict(val_features_fft)\n",
    "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft)\n",
    "print(f\"KNN (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_knn)*100:.2f}%\")\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.09%\n",
    "\n",
    "86.20% (NFFT=2048, hop_length=256, window_type='hanning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.02 seconds\n",
      "KNN (FFT features) - Validation Accuracy: 84.05%\n",
      "KNN (FFT features) - Test Accuracy: 84.24%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_knn = knn_classifier.predict(val_features_fft_scaled)\n",
    "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft_scaled)\n",
    "print(f\"KNN (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_knn)*100:.2f}%\")\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "84.86%\n",
    "\n",
    "84.13% (NFFT=2048, hop_length=256, window_type='hanning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 46.71 seconds\n",
      "Validation Accuracy (SVM with RBF Kernel): 100.00%\n",
      "Test Accuracy (SVM with RBF Kernel): 88.22%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=71.19418600172986, kernel='rbf', degree=3, gamma=0.03752055855124281, \n",
    "                         coef0=0.0, shrinking=True, probability=False, tol=0.0005319450186421158, \n",
    "                         cache_size=500, class_weight=None, verbose=False, max_iter=-1, \n",
    "                         decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Kết hợp dữ liệu train và validation để tăng lượng dữ liệu huấn luyện (coi như là 8:2)\n",
    "X_combined = np.vstack((train_features_fft, val_features_fft))\n",
    "y_combined = np.concatenate((train_labels_fft, val_labels_fft))\n",
    "\n",
    "# Huấn luyện mô hình SVM trên dữ liệu kết hợp\n",
    "svm_rbf_classifier.fit(X_combined, y_combined)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_fft_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.70%\n",
    "\n",
    "87.86% (NFFT=2048, hop_length=256, window_type='hanning')\n",
    "\n",
    "88.15% (NFFT=2048, hop_length=256, window_type='bartlett')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 56.93 seconds\n",
      "Validation Accuracy (SVM with RBF Kernel): 86.51%\n",
      "Test Accuracy (SVM with RBF Kernel): 87.61%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=71.19418600172986, kernel='rbf', degree=3, gamma=0.03752055855124281, \n",
    "                         coef0=0.0, shrinking=True, probability=False, tol=0.0005319450186421158, \n",
    "                         cache_size=500, class_weight=None, verbose=False, max_iter=-1, \n",
    "                         decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_fft_scaled)\n",
    "val_accuracy_svm_rbf = accuracy_score(val_labels_fft, val_predictions_svm_rbf)\n",
    "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft_scaled)\n",
    "scale_test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_fft_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.99%\n",
    "\n",
    "86.12% (NFFT=2048, hop_length=256, window_type='hanning')\n",
    "\n",
    "86.05% (NFFT=2048, hop_length=256, window_type='bartlett')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 11.68 seconds\n",
      "Logistic Regression (FFT features) - Validation Accuracy: 78.61%\n",
      "Logistic Regression (FFT features) - Test Accuracy: 79.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='lbfgs', max_iter=1500, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "lr_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_lr = lr_classifier.predict(val_features_fft)\n",
    "test_accuracy_fft_lr = lr_classifier.predict(test_features_fft)\n",
    "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_lr)*100:.2f}%\")\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_lr)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "79.89%\n",
    "\n",
    "79.86% (NFFT=2048, hop_length=256, window_type='hanning')\n",
    "\n",
    "80.04% (NFFT=2048, hop_length=256, window_type='bartlett')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 145.44 seconds\n",
      "Logistic Regression (FFT features) - Validation Accuracy: 78.75%\n",
      "Logistic Regression (FFT features) - Test Accuracy: 80.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='saga', max_iter=1000, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "lr_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_lr = lr_classifier.predict(val_features_fft_scaled)\n",
    "scale_test_accuracy_fft_lr = lr_classifier.predict(test_features_fft_scaled)\n",
    "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_lr)*100:.2f}%\")\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, scale_test_accuracy_fft_lr)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "79.38%\n",
    "\n",
    "80.14% (NFFT=2048, hop_length=256, window_type='hanning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 34.56 seconds\n",
      "Random Forest (FFT features) - Validation Accuracy: 84.70%\n",
      "Random Forest (FFT features) - Test Accuracy: 84.28%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                       max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                                       n_jobs=None, random_state=42, verbose=0, warm_start=False, class_weight=None, \n",
    "                                       ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "rf_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_rf = rf_classifier.predict(val_features_fft)\n",
    "test_accuracy_fft_rf = rf_classifier.predict(test_features_fft)\n",
    "print(f\"Random Forest (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_rf)*100:.2f}%\")\n",
    "print(f\"Random Forest (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_rf)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "84.53%\n",
    "\n",
    "84.78% (NFFT=2048, hop_length=256, window_type='hanning')\n",
    "\n",
    "85.58% (NFFT=2048, hop_length=256, window_type='hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 384.52 seconds\n",
      "Validation Accuracy (Extra Trees): 87.02%\n",
      "Test Accuracy (Extra Trees): 87.25%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_et = et_classifier.predict(val_features_fft)\n",
    "val_accuracy_et = accuracy_score(val_labels_fft, val_predictions_et)\n",
    "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {test_accuracy_fft_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.81%\n",
    "\n",
    "87.46% (NFFT=2048, hop_length=256, window_type='hanning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 404.47 seconds\n",
      "Validation Accuracy (Extra Trees): 86.80%\n",
      "Test Accuracy (Extra Trees): 86.45%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_et = et_classifier.predict(val_features_fft_scaled)\n",
    "val_accuracy_et = accuracy_score(val_labels_fft, val_predictions_et)\n",
    "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_fft_scaled)\n",
    "scale_test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_fft_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.81%\n",
    "\n",
    "87.28% (NFFT=2048, hop_length=256, window_type='hanning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFTs + MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc_features(signal_in, sample_rate, n_mfcc=70, n_fft=2048, \n",
    "                           hop_length=512, n_mels=128, fmax=None):\n",
    "    \"\"\"\n",
    "    Tính toán đặc trưng MFCC cho tín hiệu âm thanh.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        n_mfcc: Số lượng hệ số MFCC\n",
    "        n_fft: Kích thước FFT\n",
    "        hop_length: Bước nhảy\n",
    "        n_mels: Số lượng mel bands\n",
    "        fmax: Tần số cao nhất\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng MFCC\n",
    "    \"\"\"\n",
    "    # Tính MFCC\n",
    "    mfccs = librosa.feature.mfcc(\n",
    "        y=signal_in, \n",
    "        sr=sample_rate, \n",
    "        n_mfcc=n_mfcc,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        fmax=fmax\n",
    "    )\n",
    "    \n",
    "    # Trung bình theo thời gian để có vector đặc trưng ổn định\n",
    "    mfcc_feature = np.mean(mfccs, axis=1)\n",
    "    \n",
    "    return mfcc_feature\n",
    "\n",
    "def load_combined_features_from_directory(directory, sample_rate=22050, \n",
    "                                          NFFT=512, n_mfcc=70, \n",
    "                                          frame_size=0.025, hop_length=256, \n",
    "                                          overlap=0.6, output_dir=None, \n",
    "                                          dataset_type='train', normalize=False):\n",
    "    \"\"\"\n",
    "    Duyệt qua các file âm thanh và tính đặc trưng kết hợp FFT và MFCC.\n",
    "    \n",
    "    Args:\n",
    "        directory: Thư mục chứa dữ liệu âm thanh\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        NFFT: Số điểm FFT\n",
    "        n_mfcc: Số lượng hệ số MFCC\n",
    "        frame_size: Kích thước frame\n",
    "        hop_length: Bước nhảy\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame\n",
    "        output_dir: Thư mục đầu ra để lưu đặc trưng\n",
    "        dataset_type: Loại tập dữ liệu ('train', 'test', 'val')\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        features: Mảng đặc trưng kết hợp\n",
    "        labels: Nhãn tương ứng\n",
    "    \"\"\"\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    hop_str = f\"{hop_length}\" if hop_length else f\"overlap{overlap}\"\n",
    "    features_file = os.path.join(output_dir, f'combined_features_{dataset_type}_nfft{NFFT}_hop{hop_str}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'combined_labels_{dataset_type}_nfft{NFFT}_hop{hop_str}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        \n",
    "        for label in ['bee', 'nobee', 'noqueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Warning: Path {path} does not exist. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            for file in os.listdir(path):\n",
    "                if not file.endswith(('.wav', '.mp3', '.flac', '.ogg')):\n",
    "                    continue\n",
    "                    \n",
    "                file_path = os.path.join(path, file)\n",
    "                try:\n",
    "                    # Tải tín hiệu âm thanh\n",
    "                    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                    \n",
    "                    # Tính FFT features từ code cũ\n",
    "                    fft_feature = compute_fft_features(\n",
    "                        signal, sr, frame_size=frame_size, hop_length=hop_length, \n",
    "                        overlap=overlap, NFFT=NFFT, window_type='bartlett',\n",
    "                        normalize=normalize\n",
    "                    )\n",
    "                    \n",
    "                    # Tính MFCC features\n",
    "                    mfcc_feature = compute_mfcc_features(\n",
    "                        signal, sr, n_mfcc=n_mfcc, n_fft=NFFT, \n",
    "                        hop_length=hop_length\n",
    "                    )\n",
    "                    \n",
    "                    # Kết hợp đặc trưng FFT và MFCC\n",
    "                    combined_feature = np.concatenate([fft_feature, mfcc_feature])\n",
    "                    \n",
    "                    features.append(combined_feature)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        \n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Combined features extraction time: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Features shape: {features.shape}, Labels shape: {labels.shape}\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def pre_emphasis(signal_in, pre_emph=0.97):\n",
    "    \"\"\"\n",
    "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        pre_emph: Hệ số pre-emphasis, mặc định là 0.97\n",
    "        \n",
    "    Returns:\n",
    "        Tín hiệu sau khi áp dụng pre-emphasis\n",
    "    \"\"\"\n",
    "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
    "\n",
    "def framing(signal_in, sample_rate, frame_size=0.025, hop_length=256, overlap=0.6):\n",
    "    \"\"\"\n",
    "    Chia tín hiệu thành các frame với kích thước và bước nhảy xác định.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu frame_size > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu hop_length > 1)\n",
    "                    Nếu None, sẽ được tính dựa trên overlap\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame, mặc định là 0.6 (60%)\n",
    "                Chỉ được sử dụng khi hop_length là None\n",
    "        \n",
    "    Returns:\n",
    "        Mảng 2D chứa các frame\n",
    "    \"\"\"\n",
    "    # Xác định kích thước frame trong số mẫu\n",
    "    if frame_size <= 1:  # Nếu frame_size <= 1, xem như đơn vị là giây\n",
    "        frame_length = int(round(frame_size * sample_rate))\n",
    "    else:  # Ngược lại, xem như đơn vị là số mẫu\n",
    "        frame_length = int(frame_size)\n",
    "    \n",
    "    # Xác định hop_length (bước nhảy) trong số mẫu\n",
    "    if hop_length is None:\n",
    "        # Tính hop_length từ overlap\n",
    "        frame_step = int(frame_length * (1 - overlap))\n",
    "    elif hop_length <= 1:  # Nếu hop_length <= 1, xem như đơn vị là giây\n",
    "        frame_step = int(round(hop_length * sample_rate))\n",
    "    else:  # Ngược lại, xem như đơn vị là số mẫu\n",
    "        frame_step = int(hop_length)\n",
    "    \n",
    "    # Đảm bảo hop_length không quá nhỏ\n",
    "    frame_step = max(1, frame_step)\n",
    "    \n",
    "    signal_length = len(signal_in)\n",
    "    \n",
    "    # Tính số frame cần thiết\n",
    "    num_frames = int(np.ceil((signal_length - frame_length) / frame_step)) + 1\n",
    "    \n",
    "    # Đệm tín hiệu để đảm bảo có đủ mẫu cho tất cả các frame\n",
    "    pad_signal_length = (num_frames - 1) * frame_step + frame_length\n",
    "    pad_zeros = np.zeros(pad_signal_length - signal_length)\n",
    "    padded_signal = np.concatenate([signal_in, pad_zeros])\n",
    "    \n",
    "    # Tạo indices cho từng frame\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    \n",
    "    # Đảm bảo indices không vượt quá độ dài tín hiệu\n",
    "    indices = np.minimum(indices, len(padded_signal) - 1)\n",
    "    \n",
    "    # Trích xuất các frame từ tín hiệu\n",
    "    frames = padded_signal[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def windowing(frames, window_type='bartlett'):\n",
    "    \"\"\"\n",
    "    Áp dụng cửa sổ cho mỗi frame.\n",
    "    \n",
    "    Args:\n",
    "        frames: Mảng 2D chứa các frame\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        \n",
    "    Returns:\n",
    "        Các frame sau khi áp dụng cửa sổ\n",
    "    \"\"\"\n",
    "    frame_length = frames.shape[1]\n",
    "    \n",
    "    if window_type == 'hamming':\n",
    "        window = np.hamming(frame_length)\n",
    "    elif window_type == 'hanning':\n",
    "        window = np.hanning(frame_length)\n",
    "    elif window_type == 'blackman':\n",
    "        window = np.blackman(frame_length)\n",
    "    elif window_type == 'bartlett':\n",
    "        window = np.bartlett(frame_length)\n",
    "    else:\n",
    "        window = np.hamming(frame_length)  # Mặc định là hamming\n",
    "        \n",
    "    return frames * window\n",
    "\n",
    "def fft_frames(frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
    "    \n",
    "    Args:\n",
    "        frames: Mảng 2D chứa các frame\n",
    "        NFFT: Kích thước FFT (số điểm FFT)\n",
    "        \n",
    "    Returns:\n",
    "        Magnitude của FFT\n",
    "    \"\"\"\n",
    "    return np.absolute(np.fft.rfft(frames, NFFT))\n",
    "\n",
    "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, hop_length=256, \n",
    "                         overlap=0.6, NFFT=512, apply_log=True, window_type='bartlett',\n",
    "                         normalize=False):\n",
    "    \"\"\"\n",
    "    Tính toán đặc trưng FFT cho tín hiệu âm thanh:\n",
    "      - Pre-emphasis, Framing, Windowing.\n",
    "      - Tính FFT cho từng frame và lấy giá trị magnitude.\n",
    "      - Trung bình các frame để có vector đặc trưng ổn định.\n",
    "      \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu > 1). Nếu None, sẽ sử dụng overlap\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame (0-1)\n",
    "        NFFT: Số điểm FFT\n",
    "        apply_log: Áp dụng logarit cho đặc trưng\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng có kích thước (NFFT//2+1,)\n",
    "    \"\"\"\n",
    "    # Áp dụng pre-emphasis\n",
    "    emphasized_signal = pre_emphasis(signal_in)\n",
    "    \n",
    "    # Chia tín hiệu thành các frame\n",
    "    frames = framing(emphasized_signal, sample_rate, frame_size, hop_length, overlap)\n",
    "    \n",
    "    # Áp dụng cửa sổ\n",
    "    windowed_frames = windowing(frames, window_type)\n",
    "    \n",
    "    # Tính FFT\n",
    "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
    "    \n",
    "    # Trung bình theo các frame\n",
    "    fft_feature = np.mean(mag_frames, axis=0)\n",
    "    \n",
    "    # Áp dụng logarithm (nếu cần)\n",
    "    if apply_log:\n",
    "        fft_feature = np.log(fft_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
    "    \n",
    "    # Chuẩn hóa (nếu cần)\n",
    "    if normalize:\n",
    "        fft_feature = (fft_feature - np.mean(fft_feature)) / (np.std(fft_feature) + 1e-8)\n",
    "    \n",
    "    return fft_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from .pkl files...\n",
      "Loading val data from .pkl files...\n",
      "Loading test data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "train_features_fft, train_labels_fft = load_combined_features_from_directory(train_path, sample_rate=22050, NFFT=2048, output_dir=output_dir, dataset_type='train')\n",
    "val_features_fft, val_labels_fft = load_combined_features_from_directory(val_path, sample_rate=22050, NFFT=2048, output_dir=output_dir, dataset_type='val')\n",
    "test_features_fft, test_labels_fft = load_combined_features_from_directory(test_path, sample_rate=22050, NFFT=2048, output_dir=output_dir, dataset_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_fft_scaled = scaler.fit_transform(train_features_fft)\n",
    "val_features_fft_scaled = scaler.transform(val_features_fft)\n",
    "test_features_fft_scaled = scaler.transform(test_features_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.02 seconds\n",
      "KNN (FFT features) - Validation Accuracy: 87.24%\n",
      "KNN (FFT features) - Test Accuracy: 87.07%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_knn = knn_classifier.predict(val_features_fft)\n",
    "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft)\n",
    "print(f\"KNN (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_knn)*100:.2f}%\")\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.02 seconds\n",
      "KNN (FFT features) - Validation Accuracy: 86.66%\n",
      "KNN (FFT features) - Test Accuracy: 86.85%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_knn = knn_classifier.predict(val_features_fft_scaled)\n",
    "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft_scaled)\n",
    "print(f\"KNN (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_knn)*100:.2f}%\")\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 123.98 seconds\n",
      "Validation Accuracy (SVM with RBF Kernel): 40.25%\n",
      "Test Accuracy (SVM with RBF Kernel): 40.11%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_fft)\n",
    "val_accuracy_svm_rbf = accuracy_score(val_labels_fft, val_predictions_svm_rbf)\n",
    "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_fft_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 115.63 seconds\n",
      "Validation Accuracy (SVM with RBF Kernel): 76.21%\n",
      "Test Accuracy (SVM with RBF Kernel): 73.08%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=71.19418600172986, kernel='rbf', degree=3, gamma=0.03752055855124281, \n",
    "                         coef0=0.0, shrinking=True, probability=False, tol=0.0005319450186421158, \n",
    "                         cache_size=500, class_weight=None, verbose=False, max_iter=-1, \n",
    "                         decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_fft)\n",
    "val_accuracy_svm_rbf = accuracy_score(val_labels_fft, val_predictions_svm_rbf)\n",
    "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_fft_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 155.32 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 73.80%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=71.19418600172986, kernel='rbf', degree=3, gamma=0.03752055855124281, \n",
    "                         coef0=0.0, shrinking=True, probability=False, tol=0.0005319450186421158, \n",
    "                         cache_size=500, class_weight=None, verbose=False, max_iter=-1, \n",
    "                         decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Kết hợp dữ liệu train và validation để tăng lượng dữ liệu huấn luyện (coi như là 8:2)\n",
    "X_combined = np.vstack((train_features_fft, val_features_fft))\n",
    "y_combined = np.concatenate((train_labels_fft, val_labels_fft))\n",
    "\n",
    "# Huấn luyện mô hình SVM trên dữ liệu kết hợp\n",
    "svm_rbf_classifier.fit(X_combined, y_combined)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_fft_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 19.83 seconds\n",
      "Logistic Regression (FFT features) - Validation Accuracy: 80.42%\n",
      "Logistic Regression (FFT features) - Test Accuracy: 80.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='lbfgs', max_iter=1500, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "lr_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_lr = lr_classifier.predict(val_features_fft)\n",
    "test_accuracy_fft_lr = lr_classifier.predict(test_features_fft)\n",
    "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_lr)*100:.2f}%\")\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_lr)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 302.90 seconds\n",
      "Logistic Regression (FFT features) - Validation Accuracy: 79.77%\n",
      "Logistic Regression (FFT features) - Test Accuracy: 80.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='saga', max_iter=1000, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "lr_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_lr = lr_classifier.predict(val_features_fft_scaled)\n",
    "scale_test_accuracy_fft_lr = lr_classifier.predict(test_features_fft_scaled)\n",
    "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_lr)*100:.2f}%\")\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, scale_test_accuracy_fft_lr)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 52.99 seconds\n",
      "Random Forest (FFT features) - Validation Accuracy: 86.00%\n",
      "Random Forest (FFT features) - Test Accuracy: 86.16%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                       max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                                       n_jobs=None, random_state=42, verbose=0, warm_start=False, class_weight=None, \n",
    "                                       ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "rf_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_rf = rf_classifier.predict(val_features_fft)\n",
    "test_accuracy_fft_rf = rf_classifier.predict(test_features_fft)\n",
    "print(f\"Random Forest (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_rf)*100:.2f}%\")\n",
    "print(f\"Random Forest (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_rf)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 420.69 seconds\n",
      "Validation Accuracy (Extra Trees): 86.80%\n",
      "Test Accuracy (Extra Trees): 87.46%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_et = et_classifier.predict(val_features_fft)\n",
    "val_accuracy_et = accuracy_score(val_labels_fft, val_predictions_et)\n",
    "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {test_accuracy_fft_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 421.90 seconds\n",
      "Validation Accuracy (Extra Trees): 86.95%\n",
      "Test Accuracy (Extra Trees): 87.57%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_et = et_classifier.predict(val_features_fft_scaled)\n",
    "val_accuracy_et = accuracy_score(val_labels_fft, val_predictions_et)\n",
    "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_fft_scaled)\n",
    "scale_test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_fft_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from .pkl files...\n",
      "Loading val data from .pkl files...\n",
      "Loading test data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "def pre_emphasis(signal_in, pre_emph=0.97):\n",
    "    \"\"\"\n",
    "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        pre_emph: Hệ số pre-emphasis, mặc định là 0.97\n",
    "        \n",
    "    Returns:\n",
    "        Tín hiệu sau khi áp dụng pre-emphasis\n",
    "    \"\"\"\n",
    "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
    "\n",
    "def framing(signal_in, sample_rate, frame_size=0.025, hop_length=256, overlap=0.6):\n",
    "    \"\"\"\n",
    "    Chia tín hiệu thành các frame với kích thước và bước nhảy xác định.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu frame_size > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu hop_length > 1)\n",
    "                    Nếu None, sẽ được tính dựa trên overlap\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame, mặc định là 0.6 (60%)\n",
    "                Chỉ được sử dụng khi hop_length là None\n",
    "        \n",
    "    Returns:\n",
    "        Mảng 2D chứa các frame\n",
    "    \"\"\"\n",
    "    # Xác định kích thước frame trong số mẫu\n",
    "    if frame_size <= 1:  # Nếu frame_size <= 1, xem như đơn vị là giây\n",
    "        frame_length = int(round(frame_size * sample_rate))\n",
    "    else:  # Ngược lại, xem như đơn vị là số mẫu\n",
    "        frame_length = int(frame_size)\n",
    "    \n",
    "    # Xác định hop_length (bước nhảy) trong số mẫu\n",
    "    if hop_length is None:\n",
    "        # Tính hop_length từ overlap\n",
    "        frame_step = int(frame_length * (1 - overlap))\n",
    "    elif hop_length <= 1:  # Nếu hop_length <= 1, xem như đơn vị là giây\n",
    "        frame_step = int(round(hop_length * sample_rate))\n",
    "    else:  # Ngược lại, xem như đơn vị là số mẫu\n",
    "        frame_step = int(hop_length)\n",
    "    \n",
    "    # Đảm bảo hop_length không quá nhỏ\n",
    "    frame_step = max(1, frame_step)\n",
    "    \n",
    "    signal_length = len(signal_in)\n",
    "    \n",
    "    # Tính số frame cần thiết\n",
    "    num_frames = int(np.ceil((signal_length - frame_length) / frame_step)) + 1\n",
    "    \n",
    "    # Đệm tín hiệu để đảm bảo có đủ mẫu cho tất cả các frame\n",
    "    pad_signal_length = (num_frames - 1) * frame_step + frame_length\n",
    "    pad_zeros = np.zeros(pad_signal_length - signal_length)\n",
    "    padded_signal = np.concatenate([signal_in, pad_zeros])\n",
    "    \n",
    "    # Tạo indices cho từng frame\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    \n",
    "    # Đảm bảo indices không vượt quá độ dài tín hiệu\n",
    "    indices = np.minimum(indices, len(padded_signal) - 1)\n",
    "    \n",
    "    # Trích xuất các frame từ tín hiệu\n",
    "    frames = padded_signal[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def windowing(frames, window_type='bartlett'):\n",
    "    \"\"\"\n",
    "    Áp dụng cửa sổ cho mỗi frame.\n",
    "    \n",
    "    Args:\n",
    "        frames: Mảng 2D chứa các frame\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        \n",
    "    Returns:\n",
    "        Các frame sau khi áp dụng cửa sổ\n",
    "    \"\"\"\n",
    "    frame_length = frames.shape[1]\n",
    "    \n",
    "    if window_type == 'hamming':\n",
    "        window = np.hamming(frame_length)\n",
    "    elif window_type == 'hanning':\n",
    "        window = np.hanning(frame_length)\n",
    "    elif window_type == 'blackman':\n",
    "        window = np.blackman(frame_length)\n",
    "    elif window_type == 'bartlett':\n",
    "        window = np.bartlett(frame_length)\n",
    "    else:\n",
    "        window = np.hamming(frame_length)  # Mặc định là hamming\n",
    "        \n",
    "    return frames * window\n",
    "\n",
    "def fft_frames(frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
    "    \n",
    "    Args:\n",
    "        frames: Mảng 2D chứa các frame\n",
    "        NFFT: Kích thước FFT (số điểm FFT)\n",
    "        \n",
    "    Returns:\n",
    "        Magnitude của FFT\n",
    "    \"\"\"\n",
    "    return np.absolute(np.fft.rfft(frames, NFFT))\n",
    "\n",
    "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, hop_length=256, \n",
    "                         overlap=0.6, NFFT=512, apply_log=True, window_type='bartlett',\n",
    "                         normalize=False):\n",
    "    \"\"\"\n",
    "    Tính toán đặc trưng FFT cho tín hiệu âm thanh:\n",
    "      - Pre-emphasis, Framing, Windowing.\n",
    "      - Tính FFT cho từng frame và lấy giá trị magnitude.\n",
    "      - Trung bình các frame để có vector đặc trưng ổn định.\n",
    "      \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu > 1). Nếu None, sẽ sử dụng overlap\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame (0-1)\n",
    "        NFFT: Số điểm FFT\n",
    "        apply_log: Áp dụng logarit cho đặc trưng\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng có kích thước (NFFT//2+1,)\n",
    "    \"\"\"\n",
    "    # Áp dụng pre-emphasis\n",
    "    emphasized_signal = pre_emphasis(signal_in)\n",
    "    \n",
    "    # Chia tín hiệu thành các frame\n",
    "    frames = framing(emphasized_signal, sample_rate, frame_size, hop_length, overlap)\n",
    "    \n",
    "    # Áp dụng cửa sổ\n",
    "    windowed_frames = windowing(frames, window_type)\n",
    "    \n",
    "    # Tính FFT\n",
    "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
    "    \n",
    "    # Trung bình theo các frame\n",
    "    fft_feature = np.mean(mag_frames, axis=0)\n",
    "    \n",
    "    # Áp dụng logarithm (nếu cần)\n",
    "    if apply_log:\n",
    "        fft_feature = np.log(fft_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
    "    \n",
    "    # Chuẩn hóa (nếu cần)\n",
    "    if normalize:\n",
    "        fft_feature = (fft_feature - np.mean(fft_feature)) / (np.std(fft_feature) + 1e-8)\n",
    "    \n",
    "    return fft_feature\n",
    "\n",
    "def compute_cqt_features(signal_in, sample_rate, hop_length=512, fmin=None, \n",
    "                         n_bins=84, bins_per_octave=12, apply_log=True, normalize=False):\n",
    "    \"\"\"\n",
    "    Tính đặc trưng CQT của tín hiệu:\n",
    "      - Sử dụng librosa.cqt để tính ma trận CQT, lấy giá trị magnitude.\n",
    "      - (Tùy chọn) Áp dụng log scaling để giảm phạm vi giá trị.\n",
    "      - Trung bình theo trục thời gian (axis=1) để thu được vector đặc trưng có kích thước (n_bins,).\n",
    "      \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        hop_length: Bước nhảy giữa các cửa sổ phân tích liên tiếp\n",
    "        fmin: Tần số thấp nhất (Hz). Nếu None, librosa sẽ sử dụng mặc định\n",
    "        n_bins: Số lượng bin tần số\n",
    "        bins_per_octave: Số lượng bin cho mỗi quãng 8\n",
    "        apply_log: Áp dụng logarit cho đặc trưng\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng CQT có kích thước (n_bins,)\n",
    "    \"\"\"\n",
    "    cqt_matrix = np.abs(librosa.cqt(signal_in, sr=sample_rate, hop_length=hop_length,\n",
    "                                    fmin=fmin, n_bins=n_bins, bins_per_octave=bins_per_octave))\n",
    "    \n",
    "    # Trung bình theo trục thời gian (tính trung bình các cột)\n",
    "    cqt_feature = np.mean(cqt_matrix, axis=1)\n",
    "    \n",
    "    # Áp dụng logarithm (nếu cần)\n",
    "    if apply_log:\n",
    "        cqt_feature = np.log(cqt_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
    "    \n",
    "    # Chuẩn hóa (nếu cần)\n",
    "    if normalize:\n",
    "        cqt_feature = (cqt_feature - np.mean(cqt_feature)) / (np.std(cqt_feature) + 1e-8)\n",
    "    \n",
    "    return cqt_feature\n",
    "\n",
    "def compute_features(signal_in, sample_rate, frame_size=0.025, hop_length=512, \n",
    "                     overlap=0.6, NFFT=512, window_type='bartlett', normalize=False,\n",
    "                     fmin=None, n_bins=84, bins_per_octave=12, apply_log=True):\n",
    "    \"\"\"\n",
    "    Tính toán và kết hợp đặc trưng FFT và CQT cho tín hiệu âm thanh.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame cho FFT (giây hoặc số mẫu nếu > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu > 1)\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame (0-1) cho FFT\n",
    "        NFFT: Số điểm FFT\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        fmin: Tần số thấp nhất (Hz) cho CQT\n",
    "        n_bins: Số lượng bin tần số cho CQT\n",
    "        bins_per_octave: Số lượng bin cho mỗi quãng 8 cho CQT\n",
    "        apply_log: Áp dụng logarit cho đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng kết hợp FFT và CQT\n",
    "    \"\"\"\n",
    "    # Tính đặc trưng FFT\n",
    "    fft_feature = compute_fft_features(\n",
    "        signal_in, sample_rate, frame_size=frame_size, hop_length=hop_length, \n",
    "        overlap=overlap, NFFT=NFFT, window_type=window_type,\n",
    "        apply_log=apply_log, normalize=normalize\n",
    "    )\n",
    "    \n",
    "    # Tính đặc trưng CQT\n",
    "    cqt_feature = compute_cqt_features(\n",
    "        signal_in, sample_rate, hop_length=hop_length, fmin=fmin,\n",
    "        n_bins=n_bins, bins_per_octave=bins_per_octave,\n",
    "        apply_log=apply_log, normalize=normalize\n",
    "    )\n",
    "    \n",
    "    # Kết hợp hai đặc trưng\n",
    "    combined_feature = np.concatenate((fft_feature, cqt_feature))\n",
    "    \n",
    "    return combined_feature\n",
    "\n",
    "def load_features_from_directory(directory, sample_rate=22050, NFFT=512, \n",
    "                                 frame_size=0.025, hop_length=512, overlap=0.6,\n",
    "                                 window_type='bartlett', output_dir=None, \n",
    "                                 dataset_type='train', normalize=False,\n",
    "                                 fmin=None, n_bins=84, bins_per_octave=12):\n",
    "    \"\"\"\n",
    "    Duyệt qua các file âm thanh trong thư mục và tính đặc trưng kết hợp FFT và CQT cho mỗi file.\n",
    "    \n",
    "    Args:\n",
    "        directory: Thư mục chứa dữ liệu âm thanh\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        NFFT: Số điểm FFT\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu > 1)\n",
    "        hop_length: Bước nhảy (giây hoặc số mẫu nếu > 1)\n",
    "        overlap: Tỷ lệ chồng lấp giữa các frame (0-1)\n",
    "        window_type: Loại cửa sổ ('hamming', 'hanning', 'blackman', 'bartlett')\n",
    "        output_dir: Thư mục đầu ra để lưu đặc trưng\n",
    "        dataset_type: Loại tập dữ liệu ('train', 'test', 'val')\n",
    "        normalize: Chuẩn hóa đặc trưng\n",
    "        fmin: Tần số thấp nhất (Hz) cho CQT\n",
    "        n_bins: Số lượng bin tần số cho CQT\n",
    "        bins_per_octave: Số lượng bin cho mỗi quãng 8 cho CQT\n",
    "        \n",
    "    Returns:\n",
    "        features: Mảng đặc trưng kết hợp\n",
    "        labels: Nhãn tương ứng\n",
    "    \"\"\"\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    hop_str = f\"{hop_length}\" if hop_length else f\"overlap{overlap}\"\n",
    "    features_file = os.path.join(output_dir, f'combined_features_{dataset_type}_nfft{NFFT}_hop{hop_str}_bins{n_bins}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'combined_labels_{dataset_type}_nfft{NFFT}_hop{hop_str}_bins{n_bins}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        \n",
    "        for label in ['bee', 'nobee', 'noqueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Warning: Path {path} does not exist. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            for file in os.listdir(path):\n",
    "                if not file.endswith(('.wav', '.mp3', '.flac', '.ogg')):\n",
    "                    continue\n",
    "                    \n",
    "                file_path = os.path.join(path, file)\n",
    "                try:\n",
    "                    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                    \n",
    "                    # Tính toán đặc trưng kết hợp FFT và CQT\n",
    "                    combined_feature = compute_features(\n",
    "                        signal, sr, frame_size=frame_size, hop_length=hop_length, \n",
    "                        overlap=overlap, NFFT=NFFT, window_type=window_type,\n",
    "                        normalize=normalize, fmin=fmin, n_bins=n_bins, \n",
    "                        bins_per_octave=bins_per_octave\n",
    "                    )\n",
    "                    \n",
    "                    features.append(combined_feature)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        \n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Feature extraction time: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Features shape: {features.shape}, Labels shape: {labels.shape}\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Trích xuất đặc trưng kết hợp cho tập dữ liệu\n",
    "train_features, train_labels = load_features_from_directory(\n",
    "    train_path, sample_rate=22050, NFFT=2048, \n",
    "    hop_length=512, fmin=None, n_bins=96, bins_per_octave=12,\n",
    "    output_dir=output_dir, dataset_type='train'\n",
    ")\n",
    "\n",
    "val_features, val_labels = load_features_from_directory(\n",
    "    val_path, sample_rate=22050, NFFT=2048, \n",
    "    hop_length=512, fmin=None, n_bins=96, bins_per_octave=12,\n",
    "    output_dir=output_dir, dataset_type='val'\n",
    ")\n",
    "\n",
    "test_features, test_labels = load_features_from_directory(\n",
    "    test_path, sample_rate=22050, NFFT=2048, \n",
    "    hop_length=512, fmin=None, n_bins=96, bins_per_octave=12,\n",
    "    output_dir=output_dir, dataset_type='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9653, 1121)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_cqt = StandardScaler()\n",
    "train_features_scaled = scaler_cqt.fit_transform(train_features)\n",
    "val_features_scaled   = scaler_cqt.transform(val_features)\n",
    "test_features_scaled  = scaler_cqt.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.02 seconds\n",
      "KNN (FFT features) - Validation Accuracy: 85.35%\n",
      "KNN (FFT features) - Test Accuracy: 86.16%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_knn = knn_classifier.predict(val_features)\n",
    "test_accuracy_knn = knn_classifier.predict(test_features)\n",
    "print(f\"KNN (FFT features) - Validation Accuracy: {accuracy_score(val_labels, val_pred_knn)*100:.2f}%\")\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels, test_accuracy_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.01 seconds\n",
      "KNN (CQT) - Test Accuracy: 83.95%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier_cqt = KNeighborsClassifier(n_neighbors=1, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "knn_classifier_cqt.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_cqt_knn = knn_classifier_cqt.predict(val_features_scaled)\n",
    "test_pred_cqt_knn = knn_classifier_cqt.predict(test_features_scaled)\n",
    "\n",
    "test_accuracy_cqt_knn = accuracy_score(test_labels, test_pred_cqt_knn)\n",
    "print(f\"KNN (CQT) - Test Accuracy: {test_accuracy_cqt_knn*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 4.89 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 86.52%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=71.19418600172986, kernel='rbf', degree=3, gamma=0.03752055855124281, \n",
    "                         coef0=0.0, shrinking=True, probability=False, tol=0.0005319450186421158, \n",
    "                         cache_size=500, class_weight=None, verbose=False, max_iter=-1, \n",
    "                         decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Kết hợp dữ liệu train và validation để tăng lượng dữ liệu huấn luyện (coi như là 8:2)\n",
    "X_combined = np.vstack((train_features, val_features))\n",
    "y_combined = np.concatenate((train_labels, val_labels))\n",
    "\n",
    "# Huấn luyện mô hình SVM trên dữ liệu kết hợp\n",
    "svm_rbf_classifier.fit(X_combined, y_combined)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features)\n",
    "test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 4.17 seconds\n",
      "Validation Accuracy (SVM with RBF Kernel): 84.55%\n",
      "Test Accuracy (SVM with RBF Kernel): 85.69%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=71.19418600172986, kernel='rbf', degree=3, gamma=0.03752055855124281, \n",
    "                         coef0=0.0, shrinking=True, probability=False, tol=0.0005319450186421158, \n",
    "                         cache_size=500, class_weight=None, verbose=False, max_iter=-1, \n",
    "                         decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_scaled)\n",
    "val_accuracy_svm_rbf = accuracy_score(val_labels, val_predictions_svm_rbf)\n",
    "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_scaled)\n",
    "scale_test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 5.48 seconds\n",
      "Logistic Regression (FFT features) - Validation Accuracy: 78.03%\n",
      "Logistic Regression (FFT features) - Test Accuracy: 78.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='lbfgs', max_iter=1500, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "lr_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_lr = lr_classifier.predict(val_features)\n",
    "test_accuracy_lr = lr_classifier.predict(test_features)\n",
    "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels, val_pred_lr)*100:.2f}%\")\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels, test_accuracy_lr)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 32.41 seconds\n",
      "Logistic Regression (FFT features) - Validation Accuracy: 78.25%\n",
      "Logistic Regression (FFT features) - Test Accuracy: 78.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='saga', max_iter=1000, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "lr_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_lr = lr_classifier.predict(val_features_scaled)\n",
    "scale_test_accuracy_lr = lr_classifier.predict(test_features_scaled)\n",
    "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels, val_pred_lr)*100:.2f}%\")\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels, scale_test_accuracy_lr)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 16.19 seconds\n",
      "Random Forest (FFT features) - Validation Accuracy: 84.48%\n",
      "Random Forest (FFT features) - Test Accuracy: 84.42%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                       max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                                       n_jobs=None, random_state=42, verbose=0, warm_start=False, class_weight=None, \n",
    "                                       ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "rf_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_rf = rf_classifier.predict(val_features)\n",
    "test_accuracy_rf = rf_classifier.predict(test_features)\n",
    "print(f\"Random Forest (FFT features) - Validation Accuracy: {accuracy_score(val_labels, val_pred_rf)*100:.2f}%\")\n",
    "print(f\"Random Forest (FFT features) - Test Accuracy: {accuracy_score(test_labels, test_accuracy_rf)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 25.05 seconds\n",
      "Validation Accuracy (Extra Trees): 86.80%\n",
      "Test Accuracy (Extra Trees): 85.94%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "et_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_et = et_classifier.predict(val_features)\n",
    "val_accuracy_et = accuracy_score(val_labels, val_predictions_et)\n",
    "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features)\n",
    "test_accuracy_et = accuracy_score(test_labels, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {test_accuracy_et * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 25.29 seconds\n",
      "Validation Accuracy (Extra Trees): 86.87%\n",
      "Test Accuracy (Extra Trees): 86.01%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ validation\n",
    "val_predictions_et = et_classifier.predict(val_features_scaled)\n",
    "val_accuracy_et = accuracy_score(val_labels, val_predictions_et)\n",
    "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_scaled)\n",
    "scale_test_accuracy_et = accuracy_score(test_labels, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_et * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (Gradient Boosting): 15.12 seconds\n",
      "Validation Accuracy (Gradient Boosting): 82.67%\n",
      "Test Accuracy (Gradient Boosting): 83.66%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, \n",
    "                            max_depth=3, min_samples_split=2,\n",
    "                            min_samples_leaf=1, subsample=1.0,\n",
    "                            max_features='sqrt', random_state=42)\n",
    "\n",
    "gb_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time (Gradient Boosting): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_predictions_gb = gb_classifier.predict(val_features_scaled)\n",
    "val_accuracy_gb = accuracy_score(val_labels, val_predictions_gb)\n",
    "print(f\"Validation Accuracy (Gradient Boosting): {val_accuracy_gb * 100:.2f}%\")\n",
    "\n",
    "test_predictions_gb = gb_classifier.predict(test_features_scaled)\n",
    "test_accuracy_gb = accuracy_score(test_labels, test_predictions_gb)\n",
    "print(f\"Test Accuracy (Gradient Boosting): {test_accuracy_gb * 100:.2f}%\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:158: UserWarning: [19:04:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (XGBoost): 36.81 seconds\n",
      "Validation Accuracy (XGBoost): 84.84%\n",
      "Test Accuracy (XGBoost): 86.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chuyển đổi các nhãn từ chuỗi sang số\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "val_labels_enc = le.transform(val_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,    # Tắt cảnh báo về label encoder\n",
    "    eval_metric='logloss'       # Chỉ định hàm mất mát\n",
    ")\n",
    "xgb_classifier.fit(train_features, train_labels_enc)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time (XGBoost): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá trên bộ validation\n",
    "val_predictions_xgb = xgb_classifier.predict(val_features)\n",
    "val_accuracy_xgb = accuracy_score(val_labels_enc, val_predictions_xgb)\n",
    "print(f\"Validation Accuracy (XGBoost): {val_accuracy_xgb * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá trên bộ testing\n",
    "test_predictions_xgb = xgb_classifier.predict(test_features)\n",
    "test_accuracy_xgb = accuracy_score(test_labels_enc, test_predictions_xgb)\n",
    "print(f\"Test Accuracy (XGBoost): {test_accuracy_xgb * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 9653, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.924143\n",
      "[LightGBM] [Info] Start training from score -1.383501\n",
      "[LightGBM] [Info] Start training from score -1.042905\n",
      "\n",
      "Training time (LightGBM): 1.74 seconds\n",
      "Validation Accuracy (LightGBM): 84.70%\n",
      "Test Accuracy (LightGBM): 86.78%\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lgbm_classifier = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=30,\n",
    "    random_state=42\n",
    ")\n",
    "lgbm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTraining time (LightGBM): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá trên bộ validation\n",
    "val_predictions_lgbm = lgbm_classifier.predict(val_features)\n",
    "val_accuracy_lgbm = accuracy_score(val_labels, val_predictions_lgbm)\n",
    "print(f\"Validation Accuracy (LightGBM): {val_accuracy_lgbm * 100:.2f}%\")\n",
    "\n",
    "# Đánh giá trên bộ testing\n",
    "test_predictions_lgbm = lgbm_classifier.predict(test_features)\n",
    "test_accuracy_lgbm = accuracy_score(test_labels, test_predictions_lgbm)\n",
    "print(f\"Test Accuracy (LightGBM): {test_accuracy_lgbm * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
