{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import time\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "import librosa.display\n",
        "import scipy.fftpack as fftpack\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = 'E:/Queenless/archive/nuhive_processed/train'\n",
        "val_path = 'E:/Queenless/archive/nuhive_processed/val'\n",
        "test_path = 'E:/Queenless/archive/nuhive_processed/test'\n",
        "\n",
        "output_dir = 'E:/Queenless/kaggle_features'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MFCCs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_emphasis(signal_in, alpha=0.97):\n",
        "    \"\"\"\n",
        "    Bước 1: Pre-emphasis - Lọc thông cao\n",
        "    \"\"\"\n",
        "    emphasized_signal = np.append(signal_in[0], signal_in[1:] - alpha * signal_in[:-1]) # y(t) = x(t) - alpha*x(t-1)\n",
        "    return emphasized_signal\n",
        "\n",
        "def framing(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
        "    \"\"\"\n",
        "    Bước 2: Chia khung (Framing)\n",
        "    - frame_size: kích thước khung (số giây)\n",
        "    - frame_stride: bước nhảy giữa các khung (số giây)\n",
        "    \"\"\"\n",
        "    frame_length = int(round(frame_size * sample_rate))\n",
        "    frame_step = int(round(frame_stride * sample_rate))\n",
        "    signal_length = len(signal_in)\n",
        "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step)) + 1\n",
        "\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    # Zero-padding nếu cần\n",
        "    z = np.zeros((pad_signal_length - signal_length))\n",
        "    pad_signal = np.append(signal_in, z)\n",
        "\n",
        "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
        "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "    return frames\n",
        "\n",
        "def windowing(frames):\n",
        "    \"\"\"\n",
        "    Bước 3: Áp dụng cửa sổ Hamming cho mỗi khung\n",
        "    \"\"\"\n",
        "    frame_length = frames.shape[1]\n",
        "    hamming = np.hamming(frame_length)\n",
        "    windowed_frames = frames * hamming\n",
        "    return windowed_frames\n",
        "\n",
        "def fft_frames(frames, NFFT=512):\n",
        "    \"\"\"\n",
        "    Bước 4: Tính FFT cho mỗi khung\n",
        "    \"\"\"\n",
        "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))\n",
        "    return mag_frames\n",
        "\n",
        "def power_spectrum(mag_frames, NFFT=512):\n",
        "    \"\"\"\n",
        "    Bước 4.1: Tính phổ công suất của mỗi khung\n",
        "    \"\"\"\n",
        "    return (1.0 / NFFT) * (mag_frames ** 2)\n",
        "\n",
        "def mel_filterbank(sample_rate, NFFT, nfilt=26, low_freq=0, high_freq=None):\n",
        "    \"\"\"\n",
        "    Bước 5: Tạo Mel filterbank\n",
        "    \"\"\"\n",
        "    if high_freq is None:\n",
        "        high_freq = sample_rate / 2\n",
        "\n",
        "    # Chuyển Hz sang Mel\n",
        "    low_mel = 2595 * np.log10(1 + low_freq / 700.0)\n",
        "    high_mel = 2595 * np.log10(1 + high_freq / 700.0)\n",
        "    mel_points = np.linspace(low_mel, high_mel, nfilt + 2)\n",
        "    # Chuyển lại từ Mel sang Hz\n",
        "    hz_points = 700 * (10**(mel_points / 2595) - 1)\n",
        "    bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
        "    for m in range(1, nfilt + 1):\n",
        "        f_m_minus = int(bin[m - 1])   # giới hạn trái\n",
        "        f_m = int(bin[m])             # trung tâm\n",
        "        f_m_plus = int(bin[m + 1])    # giới hạn phải\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
        "    return fbank\n",
        "\n",
        "# Hàm tính mfccs\n",
        "def compute_mfccs(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, \n",
        "                 pre_emph=0.97, NFFT=512, nfilt=26, num_ceps=13):\n",
        "    emphasized_signal = pre_emphasis(signal_in, pre_emph)\n",
        "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
        "    windowed_frames = windowing(frames)\n",
        "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
        "    pow_frames = power_spectrum(mag_frames, NFFT)\n",
        "    fbank = mel_filterbank(sample_rate, NFFT, nfilt)\n",
        "    filter_banks = np.dot(pow_frames, fbank.T)\n",
        "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
        "    log_fbank = np.log(filter_banks)\n",
        "    mfccs = fftpack.dct(log_fbank, type=2, axis=1, norm='ortho')[:, :num_ceps]\n",
        "    return mfccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n",
            "MFCCs extraction time: 88.62 seconds\n",
            "Extracting val data...\n",
            "MFCCs extraction time: 10.31 seconds\n",
            "Extracting test data...\n",
            "MFCCs extraction time: 26.72 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def extract_mfccs_features(directory, sample_rate=22050, output_dir=None, dataset_type='train'):\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'mfccs_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'mfccs_labels_{dataset_type}.pkl')\n",
        "    data_file = os.path.join(output_dir, f'mfccs_data_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file) and os.path.exists(data_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "        data = joblib.load(data_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "        data = []  # Thêm một biến để lưu dữ liệu đầu vào (có thể là tín hiệu, ví dụ như signal hoặc các thông tin khác)\n",
        "        \n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "                mfccs = compute_mfccs(signal_in=signal, sample_rate=sr)\n",
        "                mfccs_mean = np.mean(mfccs, axis=0)\n",
        "                features.append(mfccs_mean)\n",
        "                labels.append(label)\n",
        "                data.append(signal)  # Lưu tín hiệu âm thanh gốc hoặc dữ liệu khác nếu cần\n",
        "        \n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        data = np.array(data)  # Chuyển dữ liệu sang dạng numpy array nếu cần lưu\n",
        "        \n",
        "        if output_dir:\n",
        "            # Lưu từng đối tượng riêng biệt cho train/val/test\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "            joblib.dump(data, data_file)  # Lưu tín hiệu âm thanh hoặc dữ liệu\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"MFCCs extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels, data\n",
        "\n",
        "train_features_mfccs, train_labels_mfccs, train_data_mfccs = extract_mfccs_features(train_path, output_dir=output_dir, dataset_type='train')\n",
        "val_features_mfccs, val_labels_mfccs, val_data_mfccs = extract_mfccs_features(val_path, output_dir=output_dir, dataset_type='val')\n",
        "test_features_mfccs, test_labels_mfccs, test_data_mfccs = extract_mfccs_features(test_path, output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9653, 13)\n",
            "(1379, 13)\n",
            "(2760, 13)\n"
          ]
        }
      ],
      "source": [
        "print(train_features_mfccs.shape)\n",
        "print(val_features_mfccs.shape)\n",
        "print(test_features_mfccs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-7.69012215e+01, -6.49288160e+00, -5.74182178e-01, -1.52679723e+00,\n",
              "       -5.43324555e-01, -1.29329803e+00, -1.18185219e+00, -2.59659006e-01,\n",
              "        3.90794469e-04, -1.42850865e-01, -2.83489472e-01, -3.32329969e-01,\n",
              "       -1.84998776e-01])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features_mfccs[0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features_mfccs_scaled = scaler.fit_transform(train_features_mfccs)\n",
        "val_features_mfccs_scaled = scaler.transform(val_features_mfccs)\n",
        "test_features_mfccs_scaled = scaler.transform(test_features_mfccs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCCs - RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 7.18 seconds\n",
            "Validation Accuracy: 85.57%\n",
            "Test Accuracy: 84.93%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
        "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
        "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "rf_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_predictions = rf_classifier.predict(val_features_mfccs_scaled)\n",
        "val_accuracy = accuracy_score(val_labels_mfccs, val_predictions)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "test_predictions = rf_classifier.predict(test_features_mfccs_scaled)\n",
        "test_accuracy_mfccs_rf = accuracy_score(test_labels_mfccs, test_predictions)\n",
        "print(f\"Test Accuracy: {test_accuracy_mfccs_rf * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tuning bootstrap=False from 92% to 92.38%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCCs - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 4.49 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 84.63%\n",
            "Test Accuracy (SVM with RBF Kernel): 85.11%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=10, kernel='rbf', degree=3, gamma=1, coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_mfccs)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_labels_mfccs, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_mfccs)\n",
        "test_accuracy_mfccs_svm = accuracy_score(test_labels_mfccs, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_mfccs_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 4.38 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 84.05%\n",
            "Test Accuracy (SVM with RBF Kernel): 85.33%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình SVM với data scaling\n",
        "svm_rbf_classifier = SVC(C=10, kernel='rbf', degree=3, gamma=1, coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_mfccs_scaled)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_labels_mfccs, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_mfccs_scaled)\n",
        "scale_test_accuracy_mfccs_svm = accuracy_score(test_labels_mfccs, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_mfccs_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scaling data improve from 94% to 94.05%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCCs - LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.14 seconds\n",
            "Validation Accuracy (Logistic Regression): 68.09%\n",
            "Test Accuracy (Logistic Regression): 68.33%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Logistic Regression\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='liblinear', max_iter=100, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "# Huấn luyện mô hình Logistic Regression với dữ liệu đã chuẩn hóa\n",
        "lr_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_lr = lr_classifier.predict(val_features_mfccs)\n",
        "val_accuracy_lr = accuracy_score(val_labels_mfccs, val_predictions_lr)\n",
        "print(f\"Validation Accuracy (Logistic Regression): {val_accuracy_lr * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_lr = lr_classifier.predict(test_features_mfccs)\n",
        "test_accuracy_mfccs_lr = accuracy_score(test_labels_mfccs, test_predictions_lr)\n",
        "print(f\"Test Accuracy (Logistic Regression): {test_accuracy_mfccs_lr * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.07 seconds\n",
            "Validation Accuracy (Logistic Regression): 68.38%\n",
            "Test Accuracy (Logistic Regression): 68.22%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Logistic Regression với data scaling\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='liblinear', max_iter=100, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "# Huấn luyện mô hình Logistic Regression với dữ liệu đã chuẩn hóa\n",
        "lr_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_lr = lr_classifier.predict(val_features_mfccs_scaled)\n",
        "val_accuracy_lr = accuracy_score(val_labels_mfccs, val_predictions_lr)\n",
        "print(f\"Validation Accuracy (Logistic Regression): {val_accuracy_lr * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_lr = lr_classifier.predict(test_features_mfccs_scaled)\n",
        "scale_test_accuracy_mfccs_lr = accuracy_score(test_labels_mfccs, test_predictions_lr)\n",
        "print(f\"Test Accuracy (Logistic Regression): {scale_test_accuracy_mfccs_lr * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tuned the LR model but still only has 73.28% accuracy -> problem with feature extraction method?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCCs - ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 4.53 seconds\n",
            "Validation Accuracy (Extra Trees): 86.08%\n",
            "Test Accuracy (Extra Trees): 85.54%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Extra Trees \n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "et_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_features_mfccs)\n",
        "val_accuracy_et = accuracy_score(val_labels_mfccs, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_features_mfccs)\n",
        "test_accuracy_mfccs_et = accuracy_score(test_labels_mfccs, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {test_accuracy_mfccs_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 4.78 seconds\n",
            "Validation Accuracy (Extra Trees): 86.08%\n",
            "Test Accuracy (Extra Trees): 85.54%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Extra Trees với data scaling\n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
        "et_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_features_mfccs_scaled)\n",
        "val_accuracy_et = accuracy_score(val_labels_mfccs, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_features_mfccs_scaled)\n",
        "scale_test_accuracy_mfccs_et = accuracy_score(test_labels_mfccs, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_mfccs_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model tuning improved from 92.53% to 92.97%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCCs - KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.04 seconds\n",
            "Validation Accuracy (KNN): 84.92%\n",
            "Test Accuracy (KNN): 84.93%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "# Huấn luyện mô hình KNN với dữ liệu đã chuẩn hóa\n",
        "knn_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_knn = knn_classifier.predict(val_features_mfccs)\n",
        "val_accuracy_knn = accuracy_score(val_labels_mfccs, val_predictions_knn)\n",
        "print(f\"Validation Accuracy (KNN): {val_accuracy_knn * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_knn = knn_classifier.predict(test_features_mfccs)\n",
        "test_accuracy_mfccs_knn = accuracy_score(test_labels_mfccs, test_predictions_knn)\n",
        "print(f\"Test Accuracy (KNN): {test_accuracy_mfccs_knn * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.02 seconds\n",
            "Validation Accuracy (KNN): 84.99%\n",
            "Test Accuracy (KNN): 83.84%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "# Huấn luyện mô hình KNN với dữ liệu đã chuẩn hóa\n",
        "knn_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_knn = knn_classifier.predict(val_features_mfccs_scaled)\n",
        "val_accuracy_knn = accuracy_score(val_labels_mfccs, val_predictions_knn)\n",
        "print(f\"Validation Accuracy (KNN): {val_accuracy_knn * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_knn = knn_classifier.predict(test_features_mfccs_scaled)\n",
        "scale_test_accuracy_mfccs_knn = accuracy_score(test_labels_mfccs, test_predictions_knn)\n",
        "print(f\"Test Accuracy (KNN): {scale_test_accuracy_mfccs_knn * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FFTs (with pre-emphasis, framing, windowing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_emphasis(signal_in, pre_emph=0.97):\n",
        "    \"\"\"\n",
        "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
        "    \"\"\"\n",
        "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
        "\n",
        "def framing(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
        "    \"\"\"\n",
        "    Chia tín hiệu thành các frame có kích thước và bước nhảy xác định.\n",
        "    \"\"\"\n",
        "    frame_length = int(round(frame_size * sample_rate))\n",
        "    frame_step = int(round(frame_stride * sample_rate))\n",
        "    signal_length = len(signal_in)\n",
        "    num_frames = int(np.ceil(np.abs(signal_length - frame_length) / frame_step)) + 1\n",
        "\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    z = np.zeros((pad_signal_length - signal_length))\n",
        "    pad_signal = np.append(signal_in, z)\n",
        "\n",
        "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
        "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "    return frames\n",
        "\n",
        "def windowing(frames):\n",
        "    \"\"\"\n",
        "    Áp dụng cửa sổ Hamming cho mỗi frame.\n",
        "    \"\"\"\n",
        "    frame_length = frames.shape[1]\n",
        "    hamming = np.hamming(frame_length)\n",
        "    return frames * hamming\n",
        "\n",
        "def fft_frames(frames, NFFT=512):\n",
        "    \"\"\"\n",
        "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
        "    \"\"\"\n",
        "    return np.absolute(np.fft.rfft(frames, NFFT))\n",
        "\n",
        "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, NFFT=512, apply_log=True):\n",
        "    \"\"\"\n",
        "    Tính toán đặc trưng FFT cho tín hiệu âm thanh:\n",
        "      - Pre-emphasis, Framing, Windowing.\n",
        "      - Tính FFT cho từng frame và lấy giá trị magnitude.\n",
        "      - Trung bình các frame để có vector đặc trưng ổn định.\n",
        "      - (Tùy chọn) Áp dụng log để giảm phạm vi giá trị.\n",
        "      \n",
        "    Trả về: vector đặc trưng có kích thước (NFFT/2+1,).\n",
        "    \"\"\"\n",
        "    emphasized_signal = pre_emphasis(signal_in)\n",
        "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
        "    windowed_frames = windowing(frames)\n",
        "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
        "    fft_feature = np.mean(mag_frames, axis=0)  # Trung bình theo các frame\n",
        "    if apply_log:\n",
        "        fft_feature = np.log(fft_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
        "    return fft_feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_fft_features_from_directory(directory, sample_rate=22050, NFFT=512, output_dir=None, dataset_type='train'):\n",
        "    \"\"\"\n",
        "    Duyệt qua các file âm thanh trong thư mục và tính đặc trưng FFT cho mỗi file.\n",
        "    Giả sử trong directory có hai thư mục con: 'Queen' và 'NonQueen'.\n",
        "    \n",
        "    Trả về:\n",
        "      - features: mảng đặc trưng (mỗi đặc trưng có kích thước NFFT/2+1)\n",
        "      - labels: nhãn tương ứng.\n",
        "    \"\"\"\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'fft3_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'fft3_labels_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "        \n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "                fft_feature = compute_fft_features(signal, sr, NFFT=NFFT)\n",
        "                features.append(fft_feature)\n",
        "                labels.append(label)\n",
        "        \n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        \n",
        "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
        "        if output_dir:\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"FFT extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n",
            "FFT extraction time: 40.20 seconds\n",
            "Extracting val data...\n",
            "FFT extraction time: 5.69 seconds\n",
            "Extracting test data...\n",
            "FFT extraction time: 11.69 seconds\n"
          ]
        }
      ],
      "source": [
        "train_features_fft, train_labels_fft = load_fft_features_from_directory(train_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='train')\n",
        "val_features_fft, val_labels_fft = load_fft_features_from_directory(val_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='val')\n",
        "test_features_fft, test_labels_fft = load_fft_features_from_directory(test_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features_fft_scaled = scaler.fit_transform(train_features_fft)\n",
        "val_features_fft_scaled = scaler.transform(val_features_fft)\n",
        "test_features_fft_scaled = scaler.transform(test_features_fft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FFTs - KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.01 seconds\n",
            "KNN (FFT features) - Validation Accuracy: 86.08%\n",
            "KNN (FFT features) - Test Accuracy: 86.05%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(train_features_fft, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_knn = knn_classifier.predict(val_features_fft)\n",
        "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft)\n",
        "print(f\"KNN (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_knn)*100:.2f}%\")\n",
        "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "94.25% to 95.15%, pre_emph = 0.98 => 95.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.01 seconds\n",
            "KNN (FFT features) - Validation Accuracy: 84.70%\n",
            "KNN (FFT features) - Test Accuracy: 84.75%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_knn = knn_classifier.predict(val_features_fft_scaled)\n",
        "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft_scaled)\n",
        "print(f\"KNN (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_knn)*100:.2f}%\")\n",
        "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "94.25%, pre_emph = 0.98 => 94.42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FFTs - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 6.66 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 86.15%\n",
            "Test Accuracy (SVM with RBF Kernel): 86.96%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_fft, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_fft)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_labels_fft, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft)\n",
        "test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_fft_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "97.47%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 9.28 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 86.15%\n",
            "Test Accuracy (SVM with RBF Kernel): 86.81%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_fft_scaled)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_labels_fft, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft_scaled)\n",
        "scale_test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_fft_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "97.82"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FFTs - LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 7.57 seconds\n",
            "Logistic Regression (FFT features) - Validation Accuracy: 78.97%\n",
            "Logistic Regression (FFT features) - Test Accuracy: 79.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='lbfgs', max_iter=1500, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "lr_classifier.fit(train_features_fft, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_lr = lr_classifier.predict(val_features_fft)\n",
        "test_accuracy_fft_lr = lr_classifier.predict(test_features_fft)\n",
        "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_lr)*100:.2f}%\")\n",
        "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_lr)*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 76.06 seconds\n",
            "Logistic Regression (FFT features) - Validation Accuracy: 78.10%\n",
            "Logistic Regression (FFT features) - Test Accuracy: 80.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='saga', max_iter=1000, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "lr_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_lr = lr_classifier.predict(val_features_fft_scaled)\n",
        "scale_test_accuracy_fft_lr = lr_classifier.predict(test_features_fft_scaled)\n",
        "print(f\"Logistic Regression (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_lr)*100:.2f}%\")\n",
        "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, scale_test_accuracy_fft_lr)*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tuning from 85.97% to 86.05%\n",
        "\n",
        "Using min max scaling -> 86.08%\n",
        "\n",
        "But Non-scaling data working better -> 86.33%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FFTs - RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 24.74 seconds\n",
            "Random Forest (FFT features) - Validation Accuracy: 84.70%\n",
            "Random Forest (FFT features) - Test Accuracy: 84.57%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
        "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
        "                                       max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
        "                                       n_jobs=None, random_state=42, verbose=0, warm_start=False, class_weight=None, \n",
        "                                       ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "rf_classifier.fit(train_features_fft, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_rf = rf_classifier.predict(val_features_fft)\n",
        "test_accuracy_fft_rf = rf_classifier.predict(test_features_fft)\n",
        "print(f\"Random Forest (FFT features) - Validation Accuracy: {accuracy_score(val_labels_fft, val_pred_rf)*100:.2f}%\")\n",
        "print(f\"Random Forest (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_rf)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not tuning yet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FFTs - ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 72.68 seconds\n",
            "Validation Accuracy (Extra Trees): 86.73%\n",
            "Test Accuracy (Extra Trees): 86.59%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
        "et_classifier.fit(train_features_fft, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_features_fft)\n",
        "val_accuracy_et = accuracy_score(val_labels_fft, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_features_fft)\n",
        "test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {test_accuracy_fft_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 71.75 seconds\n",
            "Validation Accuracy (Extra Trees): 86.87%\n",
            "Test Accuracy (Extra Trees): 86.81%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
        "et_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_features_fft_scaled)\n",
        "val_accuracy_et = accuracy_score(val_labels_fft, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_features_fft_scaled)\n",
        "scale_test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_fft_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "93.95% -> 95.80% beautifull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FFTs plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "def compute_fftplus_features(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, NFFT=512, apply_log=True):\n",
        "    \"\"\"\n",
        "    Tính toán đặc trưng kết hợp FFT và đặc trưng thống kê miền thời gian.\n",
        "    \n",
        "    Trả về: vector đặc trưng có kích thước (NFFT/2 + 1) + 6.\n",
        "    \"\"\"\n",
        "    # Tính đặc trưng thống kê miền thời gian từ tín hiệu gốc\n",
        "    mean_signal = np.mean(signal_in)\n",
        "    std_signal = np.std(signal_in)\n",
        "    skewness_signal = skew(signal_in)\n",
        "    kurtosis_signal = kurtosis(signal_in)\n",
        "    zcr_signal = np.mean(np.abs(np.diff(np.sign(signal_in))) > 0)  # Tỷ lệ vượt qua số 0\n",
        "    energy_signal = np.sum(signal_in**2) / len(signal_in)  # Năng lượng trung bình\n",
        "\n",
        "    # Tính đặc trưng FFT như cũ\n",
        "    emphasized_signal = pre_emphasis(signal_in)\n",
        "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
        "    windowed_frames = windowing(frames)\n",
        "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
        "    fft_feature = np.mean(mag_frames, axis=0)  # Trung bình theo các frame\n",
        "    if apply_log:\n",
        "        fft_feature = np.log(fft_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
        "\n",
        "    # Kết hợp đặc trưng FFT và đặc trưng miền thời gian\n",
        "    combined_feature = np.concatenate([\n",
        "        fft_feature,\n",
        "        [mean_signal, std_signal, skewness_signal, kurtosis_signal, zcr_signal, energy_signal]\n",
        "    ])\n",
        "    \n",
        "    return combined_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_fftplus_features_from_directory(directory, sample_rate=22050, NFFT=512, output_dir=None, dataset_type='train'):\n",
        "    \"\"\"\n",
        "    Duyệt qua các file âm thanh trong thư mục và tính đặc trưng fftplus cho mỗi file.\n",
        "    Giả sử trong directory có hai thư mục con: 'Queen' và 'NonQueen'.\n",
        "    \n",
        "    Trả về:\n",
        "      - features: mảng đặc trưng (mỗi đặc trưng có kích thước NFFT/2+1)\n",
        "      - labels: nhãn tương ứng.\n",
        "    \"\"\"\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'fftplus3_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'fftplus3_labels_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "        \n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "                fftplus_feature = compute_fftplus_features(signal, sr, NFFT=NFFT)\n",
        "                features.append(fftplus_feature)\n",
        "                labels.append(label)\n",
        "        \n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        \n",
        "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
        "        if output_dir:\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"fftplus extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n",
            "fftplus extraction time: 70.16 seconds\n",
            "Extracting val data...\n",
            "fftplus extraction time: 10.05 seconds\n",
            "Extracting test data...\n",
            "fftplus extraction time: 20.04 seconds\n"
          ]
        }
      ],
      "source": [
        "train_features_fftplus, train_labels_fftplus = load_fftplus_features_from_directory(train_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='train')\n",
        "val_features_fftplus, val_labels_fftplus = load_fftplus_features_from_directory(val_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='val')\n",
        "test_features_fftplus, test_labels_fftplus = load_fftplus_features_from_directory(test_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9653, 263)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features_fftplus.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features_fftplus_scaled = scaler.fit_transform(train_features_fftplus)\n",
        "val_features_fftplus_scaled = scaler.transform(val_features_fftplus)\n",
        "test_features_fftplus_scaled = scaler.transform(test_features_fftplus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.01 seconds\n",
            "KNN (fftplus features) - Validation Accuracy: 86.08%\n",
            "KNN (fftplus features) - Test Accuracy: 85.83%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(train_features_fftplus, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_knn = knn_classifier.predict(val_features_fftplus)\n",
        "test_accuracy_fftplus_knn = knn_classifier.predict(test_features_fftplus)\n",
        "print(f\"KNN (fftplus features) - Validation Accuracy: {accuracy_score(val_labels_fftplus, val_pred_knn)*100:.2f}%\")\n",
        "print(f\"KNN (fftplus features) - Test Accuracy: {accuracy_score(test_labels_fftplus, test_accuracy_fftplus_knn)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.01 seconds\n",
            "KNN (fftplus features) - Validation Accuracy: 84.63%\n",
            "KNN (fftplus features) - Test Accuracy: 84.13%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(train_features_fftplus_scaled, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_knn = knn_classifier.predict(val_features_fftplus_scaled)\n",
        "test_accuracy_fftplus_knn = knn_classifier.predict(test_features_fftplus_scaled)\n",
        "print(f\"KNN (fftplus features) - Validation Accuracy: {accuracy_score(val_labels_fftplus, val_pred_knn)*100:.2f}%\")\n",
        "print(f\"KNN (fftplus features) - Test Accuracy: {accuracy_score(test_labels_fftplus, test_accuracy_fftplus_knn)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 7.19 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 86.29%\n",
            "Test Accuracy (SVM with RBF Kernel): 86.67%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_fftplus, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_fftplus)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_labels_fftplus, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fftplus)\n",
        "test_accuracy_fftplus_svm = accuracy_score(test_labels_fftplus, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_fftplus_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 12.04 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 86.29%\n",
            "Test Accuracy (SVM with RBF Kernel): 85.98%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_fftplus_scaled, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_fftplus_scaled)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_labels_fftplus, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fftplus_scaled)\n",
        "scale_test_accuracy_fftplus_svm = accuracy_score(test_labels_fftplus, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_fftplus_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 8.73 seconds\n",
            "Logistic Regression (fftplus features) - Validation Accuracy: 78.39%\n",
            "Logistic Regression (fftplus features) - Test Accuracy: 79.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='lbfgs', max_iter=1500, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "lr_classifier.fit(train_features_fftplus, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_lr = lr_classifier.predict(val_features_fftplus)\n",
        "test_accuracy_fftplus_lr = lr_classifier.predict(test_features_fftplus)\n",
        "print(f\"Logistic Regression (fftplus features) - Validation Accuracy: {accuracy_score(val_labels_fftplus, val_pred_lr)*100:.2f}%\")\n",
        "print(f\"Logistic Regression (fftplus features) - Test Accuracy: {accuracy_score(test_labels_fftplus, test_accuracy_fftplus_lr)*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 82.38 seconds\n",
            "Logistic Regression (fftplus features) - Validation Accuracy: 78.25%\n",
            "Logistic Regression (fftplus features) - Test Accuracy: 79.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='saga', max_iter=1000, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "lr_classifier.fit(train_features_fftplus_scaled, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_lr = lr_classifier.predict(val_features_fftplus_scaled)\n",
        "scale_test_accuracy_fftplus_lr = lr_classifier.predict(test_features_fftplus_scaled)\n",
        "print(f\"Logistic Regression (fftplus features) - Validation Accuracy: {accuracy_score(val_labels_fftplus, val_pred_lr)*100:.2f}%\")\n",
        "print(f\"Logistic Regression (fftplus features) - Test Accuracy: {accuracy_score(test_labels_fftplus, scale_test_accuracy_fftplus_lr)*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 25.49 seconds\n",
            "Random Forest (fftplus features) - Validation Accuracy: 84.84%\n",
            "Random Forest (fftplus features) - Test Accuracy: 84.89%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
        "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
        "                                       max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
        "                                       n_jobs=None, random_state=42, verbose=0, warm_start=False, class_weight=None, \n",
        "                                       ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "rf_classifier.fit(train_features_fftplus, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_rf = rf_classifier.predict(val_features_fftplus)\n",
        "test_accuracy_fftplus_rf = rf_classifier.predict(test_features_fftplus)\n",
        "print(f\"Random Forest (fftplus features) - Validation Accuracy: {accuracy_score(val_labels_fftplus, val_pred_rf)*100:.2f}%\")\n",
        "print(f\"Random Forest (fftplus features) - Test Accuracy: {accuracy_score(test_labels_fftplus, test_accuracy_fftplus_rf)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 76.77 seconds\n",
            "Validation Accuracy (Extra Trees): 87.53%\n",
            "Test Accuracy (Extra Trees): 86.78%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
        "et_classifier.fit(train_features_fftplus, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_features_fftplus)\n",
        "val_accuracy_et = accuracy_score(val_labels_fftplus, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_features_fftplus)\n",
        "test_accuracy_fftplus_et = accuracy_score(test_labels_fftplus, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {test_accuracy_fftplus_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 76.14 seconds\n",
            "Validation Accuracy (Extra Trees): 87.16%\n",
            "Test Accuracy (Extra Trees): 86.81%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
        "et_classifier.fit(train_features_fftplus_scaled, train_labels_fftplus)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_features_fftplus_scaled)\n",
        "val_accuracy_et = accuracy_score(val_labels_fftplus, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_features_fftplus_scaled)\n",
        "scale_test_accuracy_fftplus_et = accuracy_score(test_labels_fftplus, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_fftplus_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FFTs + MFCC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pre_emphasis(signal_in, pre_emph=0.97):\n",
        "    \"\"\"\n",
        "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
        "    \"\"\"\n",
        "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
        "\n",
        "def framing(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
        "    \"\"\"\n",
        "    Chia tín hiệu thành các frame có kích thước và bước nhảy xác định.\n",
        "    \"\"\"\n",
        "    frame_length = int(round(frame_size * sample_rate))\n",
        "    frame_step = int(round(frame_stride * sample_rate))\n",
        "    signal_length = len(signal_in)\n",
        "    num_frames = int(np.ceil(np.abs(signal_length - frame_length) / frame_step)) + 1\n",
        "\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    z = np.zeros((pad_signal_length - signal_length))\n",
        "    pad_signal = np.append(signal_in, z)\n",
        "\n",
        "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
        "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "    return frames\n",
        "\n",
        "def windowing(frames):\n",
        "    \"\"\"\n",
        "    Áp dụng cửa sổ Hamming cho mỗi frame.\n",
        "    \"\"\"\n",
        "    frame_length = frames.shape[1]\n",
        "    hamming = np.hamming(frame_length)\n",
        "    return frames * hamming\n",
        "\n",
        "def fft_frames(frames, NFFT=512):\n",
        "    \"\"\"\n",
        "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
        "    \"\"\"\n",
        "    return np.absolute(np.fft.rfft(frames, NFFT))\n",
        "\n",
        "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, NFFT=512, apply_log=True):\n",
        "    \"\"\"\n",
        "    Tính toán đặc trưng FFT cho tín hiệu âm thanh.\n",
        "    \"\"\"\n",
        "    emphasized_signal = pre_emphasis(signal_in)\n",
        "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
        "    windowed_frames = windowing(frames)\n",
        "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
        "    fft_feature = np.mean(mag_frames, axis=0)\n",
        "    if apply_log:\n",
        "        fft_feature = np.log(fft_feature + 1e-8)\n",
        "    return fft_feature\n",
        "\n",
        "def compute_mfcc_features(signal_in, sample_rate, n_mfcc=13):\n",
        "    \"\"\"\n",
        "    Tính toán đặc trưng MFCC cho tín hiệu âm thanh sử dụng thư viện librosa.\n",
        "    \"\"\"\n",
        "    # Trích xuất MFCC sử dụng librosa\n",
        "    mfccs = librosa.feature.mfcc(y=signal_in, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "    # Lấy trung bình theo các frame (theo thời gian)\n",
        "    mfcc_features = np.mean(mfccs, axis=1)\n",
        "    return mfcc_features\n",
        "\n",
        "def compute_fft_mfcc(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, NFFT=512, n_mfcc=13):\n",
        "    \"\"\"\n",
        "    Kết hợp đặc trưng FFT và MFCC thành một vector duy nhất.\n",
        "    \n",
        "    Args:\n",
        "        signal_in: Tín hiệu âm thanh đầu vào\n",
        "        sample_rate: Tần số lấy mẫu\n",
        "        frame_size: Kích thước frame (giây)\n",
        "        frame_stride: Bước nhảy giữa các frame (giây)\n",
        "        NFFT: Kích thước FFT\n",
        "        n_mfcc: Số lượng hệ số MFCC\n",
        "        \n",
        "    Returns:\n",
        "        Vector đặc trưng kết hợp FFT và MFCC\n",
        "    \"\"\"\n",
        "    # Tính toán đặc trưng FFT\n",
        "    fft_features = compute_fft_features(signal_in, sample_rate, frame_size, frame_stride, NFFT)\n",
        "    \n",
        "    # Tính toán đặc trưng MFCC\n",
        "    mfcc_features = compute_mfcc_features(signal_in, sample_rate, n_mfcc)\n",
        "    \n",
        "    # Kết hợp 2 đặc trưng\n",
        "    fft_mfcc = np.concatenate((fft_features, mfcc_features))\n",
        "    \n",
        "    return fft_mfcc\n",
        "\n",
        "def load_fft_mfcc_from_directory(directory, sample_rate=22050, NFFT=512, n_mfcc=13, \n",
        "                                       output_dir=None, dataset_type='train'):\n",
        "    \"\"\"\n",
        "    Duyệt qua các file âm thanh trong thư mục và tính toán đặc trưng kết hợp (FFT + MFCC).\n",
        "    \n",
        "    Args:\n",
        "        directory: Thư mục chứa file âm thanh\n",
        "        sample_rate: Tần số lấy mẫu\n",
        "        NFFT: Kích thước FFT\n",
        "        n_mfcc: Số lượng hệ số MFCC\n",
        "        output_dir: Thư mục lưu file đặc trưng\n",
        "        dataset_type: Loại dữ liệu (train, val, test)\n",
        "        \n",
        "    Returns:\n",
        "        features: Mảng đặc trưng kết hợp\n",
        "        labels: Nhãn tương ứng\n",
        "    \"\"\"\n",
        "    # Kiểm tra nếu file đã tồn tại\n",
        "    features_file = os.path.join(output_dir, f'fft_mfcc_{dataset_type}2.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'fft_mfcc_labels_{dataset_type}2.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
        "        print(f\"Loading combined {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "    else:\n",
        "        print(f\"Extracting combined features for {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "        \n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "                \n",
        "                # Tính toán đặc trưng kết hợp\n",
        "                combined_feature = compute_fft_mfcc(signal, sr, NFFT=NFFT, n_mfcc=n_mfcc)\n",
        "                \n",
        "                features.append(combined_feature)\n",
        "                labels.append(label)\n",
        "        \n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        \n",
        "        # Lưu dữ liệu vào file\n",
        "        if output_dir:\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"Combined feature extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading combined train data from .pkl files...\n",
            "Loading combined val data from .pkl files...\n",
            "Loading combined test data from .pkl files...\n"
          ]
        }
      ],
      "source": [
        "train_fft_mfcc, train_fft_mfcc_labels = load_fft_mfcc_from_directory(\n",
        "    train_path, sample_rate=22050, NFFT=512, n_mfcc=70, output_dir=output_dir, dataset_type='train')\n",
        "val_fft_mfcc, val_fft_mfcc_labels = load_fft_mfcc_from_directory(\n",
        "    val_path, sample_rate=22050, NFFT=512, n_mfcc=70, output_dir=output_dir, dataset_type='val')\n",
        "test_fft_mfcc, test_fft_mfcc_labels = load_fft_mfcc_from_directory(\n",
        "    test_path, sample_rate=22050, NFFT=512, n_mfcc=70, output_dir=output_dir, dataset_type='test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined feature shape: (9653, 327)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Combined feature shape: {train_fft_mfcc.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "train_fft_mfcc_scaled = scaler.fit_transform(train_fft_mfcc)\n",
        "val_fft_mfcc_scaled = scaler.transform(val_fft_mfcc)\n",
        "test_fft_mfcc_scaled = scaler.transform(test_fft_mfcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 48.40 seconds\n",
            "Validation Accuracy: 85.71%\n",
            "Test Accuracy: 86.59%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
        "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
        "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "rf_classifier.fit(train_fft_mfcc_scaled, train_fft_mfcc_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_predictions = rf_classifier.predict(val_fft_mfcc_scaled)\n",
        "val_accuracy = accuracy_score(val_fft_mfcc_labels, val_predictions)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "test_predictions = rf_classifier.predict(test_fft_mfcc_scaled)\n",
        "test_accuracy_mfcc_rf = accuracy_score(test_fft_mfcc_labels, test_predictions)\n",
        "print(f\"Test Accuracy: {test_accuracy_mfcc_rf * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "def get_feature_importance(rf_model, feature_names=None):\n",
        "    \"\"\"\n",
        "    Extract feature importances from a trained Random Forest classifier\n",
        "    \n",
        "    Args:\n",
        "        rf_model: Trained RandomForestClassifier model\n",
        "        feature_names: Optional list of feature names\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with feature names and importance scores, sorted by importance\n",
        "    \"\"\"\n",
        "    # Get feature importances\n",
        "    importances = rf_model.feature_importances_\n",
        "    \n",
        "    # Create feature names if not provided\n",
        "    if feature_names is None:\n",
        "        feature_names = [f\"feature_{i}\" for i in range(len(importances))]\n",
        "    \n",
        "    # Create DataFrame for better visualization\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importances\n",
        "    })\n",
        "    \n",
        "    # Sort by importance\n",
        "    feature_importance_df = feature_importance_df.sort_values(\n",
        "        by='Importance', ascending=False\n",
        "    ).reset_index(drop=True)\n",
        "    \n",
        "    return feature_importance_df\n",
        "\n",
        "def plot_feature_importance(importance_df, top_n=20, figsize=(12, 8)):\n",
        "    \"\"\"\n",
        "    Plot the top N most important features\n",
        "    \n",
        "    Args:\n",
        "        importance_df: DataFrame with feature importances\n",
        "        top_n: Number of top features to plot\n",
        "        figsize: Figure size (width, height)\n",
        "    \"\"\"\n",
        "    # Get top N features\n",
        "    plot_data = importance_df.head(top_n)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.barplot(x='Importance', y='Feature', data=plot_data)\n",
        "    plt.title(f'Top {top_n} Feature Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def select_top_features(X, rf_model, top_n=None, threshold=None):\n",
        "    \"\"\"\n",
        "    Select top features based on importance from Random Forest model\n",
        "    \n",
        "    Args:\n",
        "        X: Original feature matrix\n",
        "        rf_model: Trained RandomForestClassifier model\n",
        "        top_n: Number of top features to select (optional)\n",
        "        threshold: Minimum importance threshold (optional)\n",
        "        \n",
        "    Returns:\n",
        "        X_reduced: Feature matrix with only selected features\n",
        "        selected_indices: Indices of selected features\n",
        "    \"\"\"\n",
        "    if top_n is not None:\n",
        "        # Get indices of top N features\n",
        "        indices = np.argsort(rf_model.feature_importances_)[::-1][:top_n]\n",
        "        X_reduced = X[:, indices]\n",
        "        return X_reduced, indices\n",
        "    \n",
        "    elif threshold is not None:\n",
        "        # Use scikit-learn's SelectFromModel\n",
        "        sfm = SelectFromModel(rf_model, threshold=threshold)\n",
        "        X_reduced = sfm.fit_transform(X, None)\n",
        "        selected_indices = np.where(sfm.get_support())[0]\n",
        "        return X_reduced, selected_indices\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(\"Either top_n or threshold must be specified\")\n",
        "\n",
        "# Example usage (add this to your code)\n",
        "def analyze_feature_importance(rf_classifier, X_train, X_test, train_labels, test_labels, \n",
        "                              n_features_to_select=100):\n",
        "    \"\"\"\n",
        "    Analyze feature importance, select top features and evaluate model performance\n",
        "    \n",
        "    Args:\n",
        "        rf_classifier: Trained RandomForestClassifier model\n",
        "        X_train: Training feature matrix\n",
        "        X_test: Testing feature matrix\n",
        "        train_labels: Training labels\n",
        "        test_labels: Testing labels\n",
        "        n_features_to_select: Number of top features to select\n",
        "        \n",
        "    Returns:\n",
        "        top_features_df: DataFrame with top features and their importance\n",
        "        X_train_reduced: Reduced training feature matrix\n",
        "        X_test_reduced: Reduced testing feature matrix\n",
        "        selected_indices: Indices of selected features\n",
        "    \"\"\"\n",
        "    # Generate feature names (assuming combined FFT and MFCC features)\n",
        "    n_features = X_train.shape[1]\n",
        "    n_fft = n_features - 70  # Assuming 70 MFCC features as per your code\n",
        "    feature_names = [f\"FFT_{i}\" for i in range(n_fft)]\n",
        "    feature_names.extend([f\"MFCC_{i}\" for i in range(70)])\n",
        "    \n",
        "    # Get and plot feature importance\n",
        "    importance_df = get_feature_importance(rf_classifier, feature_names)\n",
        "    plot_feature_importance(importance_df, top_n=20)\n",
        "    \n",
        "    # Select top features\n",
        "    X_train_reduced, selected_indices = select_top_features(\n",
        "        X_train, rf_classifier, top_n=n_features_to_select\n",
        "    )\n",
        "    X_test_reduced = X_test[:, selected_indices]\n",
        "    \n",
        "    # Train a new model with reduced features\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    \n",
        "    rf_reduced = RandomForestClassifier(n_estimators=100, random_state=42, bootstrap=False)\n",
        "    rf_reduced.fit(X_train_reduced, train_labels)\n",
        "    \n",
        "    # Evaluate\n",
        "    test_pred_reduced = rf_reduced.predict(X_test_reduced)\n",
        "    test_accuracy_reduced = accuracy_score(test_labels, test_pred_reduced)\n",
        "    \n",
        "    print(f\"Original model features: {n_features}\")\n",
        "    print(f\"Reduced model features: {n_features_to_select}\")\n",
        "    print(f\"Reduced model test accuracy: {test_accuracy_reduced * 100:.2f}%\")\n",
        "    \n",
        "    return importance_df, X_train_reduced, X_test_reduced, selected_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original model features: 327\n",
            "Reduced model features: 200\n",
            "Reduced model test accuracy: 87.07%\n",
            "Top 10 most important features:\n",
            "   Feature  Importance\n",
            "0    FFT_4    0.024500\n",
            "1  MFCC_14    0.023038\n",
            "2  MFCC_27    0.014570\n",
            "3   MFCC_0    0.014160\n",
            "4    FFT_1    0.013486\n",
            "5   FFT_70    0.013125\n",
            "6    FFT_2    0.012145\n",
            "7    FFT_3    0.012077\n",
            "8  FFT_186    0.012024\n",
            "9  MFCC_12    0.011737\n",
            "\n",
            "Classification Report for Optimized Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bee       0.89      0.96      0.92      1095\n",
            "       nobee       0.84      0.60      0.70       692\n",
            "     noqueen       0.86      0.97      0.91       973\n",
            "\n",
            "    accuracy                           0.87      2760\n",
            "   macro avg       0.87      0.84      0.84      2760\n",
            "weighted avg       0.87      0.87      0.86      2760\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# After training your Random Forest model, analyze feature importance\n",
        "importance_df, train_reduced, test_reduced, selected_indices = analyze_feature_importance(\n",
        "    rf_classifier,\n",
        "    train_fft_mfcc_scaled,\n",
        "    test_fft_mfcc_scaled,\n",
        "    train_fft_mfcc_labels,\n",
        "    test_fft_mfcc_labels,\n",
        "    n_features_to_select=200  # Select top 100 features\n",
        ")\n",
        "\n",
        "# Save the important features for future use\n",
        "top_features_file = os.path.join(output_dir, 'top_features.pkl')\n",
        "joblib.dump({\n",
        "    'importance_df': importance_df,\n",
        "    'selected_indices': selected_indices\n",
        "}, top_features_file)\n",
        "\n",
        "print(\"Top 10 most important features:\")\n",
        "print(importance_df.head(10))\n",
        "\n",
        "# Optional: Train a new model with only the most important features\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_optimized = RandomForestClassifier(\n",
        "    n_estimators=100, \n",
        "    criterion='gini',\n",
        "    bootstrap=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_optimized.fit(train_reduced, train_fft_mfcc_labels)\n",
        "test_pred_optimized = rf_optimized.predict(test_reduced)\n",
        "\n",
        "print(\"\\nClassification Report for Optimized Model:\")\n",
        "print(classification_report(test_fft_mfcc_labels, test_pred_optimized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "87.07"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 11.67 seconds\n",
            "Validation Accuracy (Logistic Regression): 79.91%\n",
            "Test Accuracy (Logistic Regression): 80.69%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Logistic Regression với data scaling\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='liblinear', max_iter=100, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "# Huấn luyện mô hình Logistic Regression với dữ liệu đã chuẩn hóa\n",
        "lr_classifier.fit(train_fft_mfcc_scaled, train_fft_mfcc_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_lr = lr_classifier.predict(val_fft_mfcc_scaled)\n",
        "val_accuracy_lr = accuracy_score(val_fft_mfcc_labels, val_predictions_lr)\n",
        "print(f\"Validation Accuracy (Logistic Regression): {val_accuracy_lr * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_lr = lr_classifier.predict(test_fft_mfcc_scaled)\n",
        "scale_test_accuracy_mfcc_lr = accuracy_score(test_fft_mfcc_labels, test_predictions_lr)\n",
        "print(f\"Test Accuracy (Logistic Regression): {scale_test_accuracy_mfcc_lr * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 102.03 seconds\n",
            "Validation Accuracy (Extra Trees): 86.95%\n",
            "Test Accuracy (Extra Trees): 87.61%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Extra Trees \n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "et_classifier.fit(train_fft_mfcc, train_fft_mfcc_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_fft_mfcc)\n",
        "val_accuracy_et = accuracy_score(val_fft_mfcc_labels, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_fft_mfcc)\n",
        "test_accuracy_mfcc_et = accuracy_score(test_fft_mfcc_labels, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {test_accuracy_mfcc_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.01 seconds\n",
            "Validation Accuracy (KNN): 87.09%\n",
            "Test Accuracy (KNN): 86.74%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "# Huấn luyện mô hình KNN với dữ liệu đã chuẩn hóa\n",
        "knn_classifier.fit(train_fft_mfcc_scaled, train_fft_mfcc_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_knn = knn_classifier.predict(val_fft_mfcc_scaled)\n",
        "val_accuracy_knn = accuracy_score(val_fft_mfcc_labels, val_predictions_knn)\n",
        "print(f\"Validation Accuracy (KNN): {val_accuracy_knn * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_knn = knn_classifier.predict(test_fft_mfcc_scaled)\n",
        "scale_test_accuracy_mfcc_knn = accuracy_score(test_fft_mfcc_labels, test_predictions_knn)\n",
        "print(f\"Test Accuracy (KNN): {scale_test_accuracy_mfcc_knn * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 6.25 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 86.00%\n",
            "Test Accuracy (SVM with RBF Kernel): 86.05%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=8.31, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_fft_mfcc_scaled, train_fft_mfcc_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_fft_mfcc_scaled)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_fft_mfcc_labels, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_fft_mfcc_scaled)\n",
        "scale_test_accuracy_mfcc_svm = accuracy_score(test_fft_mfcc_labels, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_mfcc_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MFCC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_mfcc(file_path, n_mfcc=13):\n",
        "    y, sr = librosa.load(file_path, sr=16000)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, dct_type=2, norm='ortho', lifter=0)\n",
        "    return mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train data from .pkl files...\n",
            "Loading val data from .pkl files...\n",
            "Loading test data from .pkl files...\n"
          ]
        }
      ],
      "source": [
        "def extract_mfcc_features(directory, sample_rate=22050, output_dir=None, dataset_type='train', reduce_dimension=True):\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'mfcc2_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'mfcc2_labels_{dataset_type}.pkl')\n",
        "    data_file = os.path.join(output_dir, f'mfcc2_data_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file) and os.path.exists(data_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "        data = joblib.load(data_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "        data = []  # Thêm một biến để lưu dữ liệu đầu vào (có thể là tín hiệu, ví dụ như signal hoặc các thông tin khác)\n",
        "        \n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                mfcc = compute_mfcc(file_path=file_path, n_mfcc=70)  # Chiết xuất MFCC cho mỗi tệp âm thanh\n",
        "                features.append(mfcc)  # Lưu ma trận MFCC cho mỗi tệp âm thanh\n",
        "                labels.append(label)\n",
        "        \n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        data = np.array(data)  # Chuyển dữ liệu sang dạng numpy array nếu cần lưu\n",
        "        \n",
        "        # Nếu cần giảm chiều theo axis=2\n",
        "        if reduce_dimension:\n",
        "            features = np.mean(features, axis=2)\n",
        "        \n",
        "        if output_dir:\n",
        "            # Lưu từng đối tượng riêng biệt cho train/val/test\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "            joblib.dump(data, data_file)  # Lưu tín hiệu âm thanh hoặc dữ liệu\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"MFCC extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels, data\n",
        "\n",
        "# Gọi hàm với tham số reduce_dimension=True để giảm chiều ngay khi gọi hàm\n",
        "train_features_mfcc, train_labels_mfcc, train_data_mfcc = extract_mfcc_features(train_path, output_dir=output_dir, dataset_type='train')\n",
        "val_features_mfcc, val_labels_mfcc, val_data_mfcc = extract_mfcc_features(val_path, output_dir=output_dir, dataset_type='val')\n",
        "test_features_mfcc, test_labels_mfcc, test_data_mfcc = extract_mfcc_features(test_path, output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9653, 70)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features_mfcc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features_mfcc_scaled = scaler.fit_transform(train_features_mfcc)\n",
        "val_features_mfcc_scaled = scaler.transform(val_features_mfcc)\n",
        "test_features_mfcc_scaled = scaler.transform(test_features_mfcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 19.69 seconds\n",
            "Validation Accuracy: 85.50%\n",
            "Test Accuracy: 86.49%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
        "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
        "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "rf_classifier.fit(train_features_mfcc_scaled, train_labels_mfcc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_predictions = rf_classifier.predict(val_features_mfcc_scaled)\n",
        "val_accuracy = accuracy_score(val_labels_mfcc, val_predictions)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "test_predictions = rf_classifier.predict(test_features_mfcc_scaled)\n",
        "test_accuracy_mfcc_rf = accuracy_score(test_labels_mfcc, test_predictions)\n",
        "print(f\"Test Accuracy: {test_accuracy_mfcc_rf * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.65 seconds\n",
            "Validation Accuracy (Logistic Regression): 79.55%\n",
            "Test Accuracy (Logistic Regression): 78.77%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Logistic Regression với data scaling\n",
        "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
        "                                   class_weight=None, random_state=42, solver='liblinear', max_iter=100, multi_class='deprecated', \n",
        "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "# Huấn luyện mô hình Logistic Regression với dữ liệu đã chuẩn hóa\n",
        "lr_classifier.fit(train_features_mfcc_scaled, train_labels_mfcc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_lr = lr_classifier.predict(val_features_mfcc_scaled)\n",
        "val_accuracy_lr = accuracy_score(val_labels_mfcc, val_predictions_lr)\n",
        "print(f\"Validation Accuracy (Logistic Regression): {val_accuracy_lr * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_lr = lr_classifier.predict(test_features_mfcc_scaled)\n",
        "scale_test_accuracy_mfcc_lr = accuracy_score(test_labels_mfcc, test_predictions_lr)\n",
        "print(f\"Test Accuracy (Logistic Regression): {scale_test_accuracy_mfcc_lr * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 21.03 seconds\n",
            "Validation Accuracy (Extra Trees): 86.15%\n",
            "Test Accuracy (Extra Trees): 86.74%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Khởi tạo mô hình Extra Trees \n",
        "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "et_classifier.fit(train_features_mfcc, train_labels_mfcc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_et = et_classifier.predict(val_features_mfcc)\n",
        "val_accuracy_et = accuracy_score(val_labels_mfcc, val_predictions_et)\n",
        "print(f\"Validation Accuracy (Extra Trees): {val_accuracy_et * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_et = et_classifier.predict(test_features_mfcc)\n",
        "test_accuracy_mfcc_et = accuracy_score(test_labels_mfcc, test_predictions_et)\n",
        "print(f\"Test Accuracy (Extra Trees): {test_accuracy_mfcc_et * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.00 seconds\n",
            "Validation Accuracy (KNN): 86.58%\n",
            "Test Accuracy (KNN): 85.94%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "# Huấn luyện mô hình KNN với dữ liệu đã chuẩn hóa\n",
        "knn_classifier.fit(train_features_mfcc_scaled, train_labels_mfcc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_knn = knn_classifier.predict(val_features_mfcc_scaled)\n",
        "val_accuracy_knn = accuracy_score(val_labels_mfcc, val_predictions_knn)\n",
        "print(f\"Validation Accuracy (KNN): {val_accuracy_knn * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_knn = knn_classifier.predict(test_features_mfcc_scaled)\n",
        "scale_test_accuracy_mfcc_knn = accuracy_score(test_labels_mfcc, test_predictions_knn)\n",
        "print(f\"Test Accuracy (KNN): {scale_test_accuracy_mfcc_knn * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 3.24 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 87.74%\n",
            "Test Accuracy (SVM with RBF Kernel): 87.32%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=8.31, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_mfcc_scaled, train_labels_mfcc)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_mfcc_scaled)\n",
        "val_accuracy_svm_rbf = accuracy_score(val_labels_mfcc, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_svm_rbf * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_mfcc_scaled)\n",
        "scale_test_accuracy_mfcc_svm = accuracy_score(test_labels_mfcc, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_mfcc_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "98.55%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STFTs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "def apply_preprocessing(signal_in, sample_rate):\n",
        "    \"\"\"\n",
        "    Apply optional preprocessing steps on the signal:\n",
        "      - Apply pre-emphasis filtering.\n",
        "    \"\"\"\n",
        "    # Pre-emphasis filter: Boosting higher frequencies slightly\n",
        "    pre_emphasis = 0.95\n",
        "    signal_in = np.append(signal_in[0], signal_in[1:] - pre_emphasis * signal_in[:-1])\n",
        "    return signal_in\n",
        "\n",
        "def compute_stfts_features(signal_in, sample_rate, n_fft=2048, hop_length=512, apply_log=True):\n",
        "    \"\"\"\n",
        "    Compute stfts features with improvements:\n",
        "      - Apply windowing (Hanning window).\n",
        "      - Optional log scaling with dynamic range compression.\n",
        "      - Optional normalization and energy-based features.\n",
        "    \"\"\"\n",
        "    # Apply preprocessing (e.g., pre-emphasis)\n",
        "    signal_in = apply_preprocessing(signal_in, sample_rate)\n",
        "    \n",
        "    # Compute stfts with a window function to avoid spectral leakage\n",
        "    stfts_matrix = np.abs(librosa.stft(signal_in, n_fft=n_fft, hop_length=hop_length, window='hann'))\n",
        "    \n",
        "    # Optional: Apply logarithmic scaling (dynamic range compression)\n",
        "    if apply_log:\n",
        "        stfts_matrix = np.log(stfts_matrix + 1e-10)  # More robust epsilon for log scaling\n",
        "\n",
        "    # Feature extraction: Mean and additional energy-based features (e.g., variance)\n",
        "    features_mean = np.mean(stfts_matrix, axis=1)\n",
        "    features_variance = np.var(stfts_matrix, axis=1)\n",
        "    \n",
        "    # Combine mean and variance (you could also add other stats like median or skewness)\n",
        "    features = np.concatenate([features_mean, features_variance], axis=0)\n",
        "\n",
        "    # Normalize the features (optional)\n",
        "    features = (features - np.mean(features)) / np.std(features)  # Z-score normalization\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n",
            "STFTs extraction time: 52.09 seconds\n",
            "Extracting val data...\n",
            "STFTs extraction time: 7.67 seconds\n",
            "Extracting test data...\n",
            "STFTs extraction time: 14.84 seconds\n"
          ]
        }
      ],
      "source": [
        "def load_stfts_features_from_directory(directory, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=None, dataset_type='train'):\n",
        "    \"\"\"\n",
        "    Load and compute stfts features from audio files in a directory, with improved accuracy.\n",
        "    Assumes 'Queen' and 'NonQueen' subdirectories are present.\n",
        "    \"\"\"\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'stfts_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'stfts_labels_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "\n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                # Load audio file\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "\n",
        "                # Compute stfts features\n",
        "                stfts_feature = compute_stfts_features(signal, sr, n_fft=n_fft, hop_length=hop_length, apply_log=True)\n",
        "\n",
        "                features.append(stfts_feature)\n",
        "                labels.append(label)\n",
        "\n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
        "        if output_dir:\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"STFTs extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels\n",
        "\n",
        "train_features_stfts, train_labels_stfts = load_stfts_features_from_directory(train_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='train')\n",
        "val_features_stfts, val_labels_stfts = load_stfts_features_from_directory(val_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='val')\n",
        "test_features_stfts, test_labels_stfts = load_stfts_features_from_directory(test_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_stfts = StandardScaler()\n",
        "train_features_stfts_scaled = scaler_stfts.fit_transform(train_features_stfts)\n",
        "val_features_stfts_scaled   = scaler_stfts.transform(val_features_stfts)\n",
        "test_features_stfts_scaled  = scaler_stfts.transform(test_features_stfts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "STFTs - KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.00 seconds\n",
            "KNN (STFTs) - Test Accuracy: 84.75%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier_stfts = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                           metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "knn_classifier_stfts.fit(train_features_stfts, train_labels_stfts)\n",
        "val_pred_stfts_knn = knn_classifier_stfts.predict(val_features_stfts)\n",
        "test_pred_stfts_knn = knn_classifier_stfts.predict(test_features_stfts)\n",
        "\n",
        "test_accuracy_stfts_knn = accuracy_score(test_labels_stfts, test_pred_stfts_knn)\n",
        "print(f\"KNN (STFTs) - Test Accuracy: {test_accuracy_stfts_knn*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Old 95.10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.00 seconds\n",
            "KNN (STFTs) - Test Accuracy: 78.37%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier_stfts = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                           metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "knn_classifier_stfts.fit(train_features_stfts_scaled, train_labels_stfts)\n",
        "val_pred_stfts_knn = knn_classifier_stfts.predict(val_features_stfts_scaled)\n",
        "test_pred_stfts_knn = knn_classifier_stfts.predict(test_features_stfts_scaled)\n",
        "\n",
        "test_accuracy_stfts_knn = accuracy_score(test_labels_stfts, test_pred_stfts_knn)\n",
        "print(f\"KNN (STFTs) - Test Accuracy: {test_accuracy_stfts_knn*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Old 94.50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "STFTs - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 122.52 seconds\n",
            "Validation Accuracy (SVM with RBF Kernel): 81.36%\n",
            "Test Accuracy (SVM with RBF Kernel): 82.79%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_rbf_classifier = SVC(C=10, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_stfts_scaled, train_labels_stfts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_stfts_scaled)\n",
        "val_accuracy_stfts_svm = accuracy_score(val_labels_stfts, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_stfts_svm * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_stfts_scaled)\n",
        "scale_test_accuracy_stfts_svm = accuracy_score(test_labels_stfts, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_stfts_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "STFTs - LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 50.48 seconds\n",
            "Logistic Regression (STFTs) - Test Accuracy: 77.50%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "lr_classifier_stfts = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', penalty= 'l2', C= 0.08858667904100823)\n",
        "lr_classifier_stfts.fit(train_features_stfts_scaled, train_labels_stfts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_stfts_lr = lr_classifier_stfts.predict(val_features_stfts_scaled)\n",
        "test_pred_stfts_lr = lr_classifier_stfts.predict(test_features_stfts_scaled)\n",
        "\n",
        "test_accuracy_stfts_lr = accuracy_score(test_labels_stfts, test_pred_stfts_lr)\n",
        "print(f\"Logistic Regression (STFTs) - Test Accuracy: {test_accuracy_stfts_lr*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "STFTs - RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 142.19 seconds\n",
            "Random Forest (STFTs) - Test Accuracy: 82.28%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier_stfts = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
        "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
        "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "rf_classifier_stfts.fit(train_features_stfts, train_labels_stfts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_stfts_rf = rf_classifier_stfts.predict(val_features_stfts)\n",
        "test_pred_stfts_rf = rf_classifier_stfts.predict(test_features_stfts)\n",
        "\n",
        "test_accuracy_stfts_rf = accuracy_score(test_labels_stfts, test_pred_stfts_rf)\n",
        "print(f\"Random Forest (STFTs) - Test Accuracy: {test_accuracy_stfts_rf*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "STFTs - ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 157.38 seconds\n",
            "Extra Trees (STFTs) - Test Accuracy: 81.05%\n"
          ]
        }
      ],
      "source": [
        "start_time\n",
        "\n",
        "et_classifier_stfts = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "et_classifier_stfts.fit(train_features_stfts_scaled, train_labels_stfts)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_stfts_et = et_classifier_stfts.predict(val_features_stfts_scaled)\n",
        "test_pred_stfts_et = et_classifier_stfts.predict(test_features_stfts_scaled)\n",
        "\n",
        "test_accuracy_stfts_et = accuracy_score(test_labels_stfts, test_pred_stfts_et)\n",
        "print(f\"Extra Trees (STFTs) - Test Accuracy: {test_accuracy_stfts_et*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def compute_stft_features(signal_in, sample_rate, n_fft=2048, hop_length=512, apply_log=True):\n",
        "    \"\"\"\n",
        "    Tính đặc trưng STFT của tín hiệu:\n",
        "      - Tính STFT bằng librosa.stft và lấy giá trị magnitude.\n",
        "      - (Tùy chọn) Áp dụng log scaling.\n",
        "      - Trung bình theo trục thời gian (axis=1) để thu được vector đặc trưng có kích thước (n_fft/2+1,).\n",
        "    \"\"\"\n",
        "    stft_matrix = np.abs(librosa.stft(signal_in, n_fft=n_fft, hop_length=hop_length))\n",
        "    if apply_log:\n",
        "        stft_matrix = np.log(stft_matrix + 1e-8)  # Thêm epsilon để tránh log(0)\n",
        "    # Trung bình theo trục thời gian (tính trung bình các cột)\n",
        "    features = np.mean(stft_matrix, axis=1)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n",
            "stft extraction time: 157.24 seconds\n",
            "Extracting val data...\n",
            "stft extraction time: 22.86 seconds\n",
            "Extracting test data...\n",
            "stft extraction time: 40.08 seconds\n"
          ]
        }
      ],
      "source": [
        "def load_stft_features_from_directory(directory, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=None, dataset_type='train'):\n",
        "    \"\"\"\n",
        "    Load and compute stft features from audio files in a directory, with improved accuracy.\n",
        "    Assumes 'Queen' and 'NonQueen' subdirectories are present.\n",
        "    \"\"\"\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'stft_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'stft_labels_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "\n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                # Load audio file\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "\n",
        "                # Compute stft features\n",
        "                stft_feature = compute_stft_features(signal, sr, n_fft=n_fft, hop_length=hop_length, apply_log=True)\n",
        "\n",
        "                features.append(stft_feature)\n",
        "                labels.append(label)\n",
        "\n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
        "        if output_dir:\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"stft extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels\n",
        "\n",
        "train_features_stft, train_labels_stft = load_stft_features_from_directory(train_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='train')\n",
        "val_features_stft, val_labels_stft = load_stft_features_from_directory(val_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='val')\n",
        "test_features_stft, test_labels_stft = load_stft_features_from_directory(test_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_stft = StandardScaler()\n",
        "train_features_stft_scaled = scaler_stft.fit_transform(train_features_stft)\n",
        "val_features_stft_scaled   = scaler_stft.transform(val_features_stft)\n",
        "test_features_stft_scaled  = scaler_stft.transform(test_features_stft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN (STFT) - Test Accuracy: 82.36%\n"
          ]
        }
      ],
      "source": [
        "knn_classifier_stft = KNeighborsClassifier(n_neighbors=25)\n",
        "knn_classifier_stft.fit(train_features_stft_scaled, train_labels_stft)\n",
        "val_pred_stft_knn = knn_classifier_stft.predict(val_features_stft_scaled)\n",
        "test_pred_stft_knn = knn_classifier_stft.predict(test_features_stft_scaled)\n",
        "\n",
        "test_accuracy_stft_knn = accuracy_score(test_labels_stft, test_pred_stft_knn)\n",
        "print(f\"KNN (STFT) - Test Accuracy: {test_accuracy_stft_knn*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy (SVM with RBF Kernel): 84.55%\n",
            "Test Accuracy (SVM with RBF Kernel): 84.53%\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo mô hình SVM với data scaling\n",
        "svm_rbf_classifier = SVC(C=10, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, \n",
        "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
        "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
        "\n",
        "# Huấn luyện mô hình SVM\n",
        "svm_rbf_classifier.fit(train_features_stft_scaled, train_labels_stft)\n",
        "\n",
        "# Đánh giá mô hình trên bộ validation\n",
        "val_predictions_svm_rbf = svm_rbf_classifier.predict(val_features_stft_scaled)\n",
        "val_accuracy_stft_svm = accuracy_score(val_labels_stft, val_predictions_svm_rbf)\n",
        "print(f\"Validation Accuracy (SVM with RBF Kernel): {val_accuracy_stft_svm * 100:.2f}%\")\n",
        "\n",
        "# Đánh giá mô hình trên bộ testing\n",
        "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_stft_scaled)\n",
        "scale_test_accuracy_stft_svm = accuracy_score(test_labels_stft, test_predictions_svm_rbf)\n",
        "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_stft_svm * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (STFT) - Test Accuracy: 79.93%\n"
          ]
        }
      ],
      "source": [
        "lr_classifier_stft = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', penalty= 'l2', C= 0.08858667904100823)\n",
        "lr_classifier_stft.fit(train_features_stft_scaled, train_labels_stft)\n",
        "val_pred_stft_lr = lr_classifier_stft.predict(val_features_stft_scaled)\n",
        "test_pred_stft_lr = lr_classifier_stft.predict(test_features_stft_scaled)\n",
        "\n",
        "test_accuracy_stft_lr = accuracy_score(test_labels_stft, test_pred_stft_lr)\n",
        "print(f\"Logistic Regression (STFT) - Test Accuracy: {test_accuracy_stft_lr*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest (STFT) - Test Accuracy: 82.90%\n"
          ]
        }
      ],
      "source": [
        "rf_classifier_stft = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier_stft.fit(train_features_stft, train_labels_stft)\n",
        "val_pred_stft_rf = rf_classifier_stft.predict(val_features_stft)\n",
        "test_pred_stft_rf = rf_classifier_stft.predict(test_features_stft)\n",
        "\n",
        "test_accuracy_stft_rf = accuracy_score(test_labels_stft, test_pred_stft_rf)\n",
        "print(f\"Random Forest (STFT) - Test Accuracy: {test_accuracy_stft_rf*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extra Trees (STFT) - Test Accuracy: 82.50%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et_classifier_stft = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "et_classifier_stft.fit(train_features_stft_scaled, train_labels_stft)\n",
        "val_pred_stft_et = et_classifier_stft.predict(val_features_stft_scaled)\n",
        "test_pred_stft_et = et_classifier_stft.predict(test_features_stft_scaled)\n",
        "\n",
        "test_accuracy_stft_et = accuracy_score(test_labels_stft, test_pred_stft_et)\n",
        "print(f\"Extra Trees (STFT) - Test Accuracy: {test_accuracy_stft_et*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CQT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_cqt_features(signal_in, sample_rate, hop_length=512, fmin=None, \n",
        "                         n_bins=84, bins_per_octave=12, apply_log=True):\n",
        "    \"\"\"\n",
        "    Tính đặc trưng CQT của tín hiệu:\n",
        "      - Sử dụng librosa.cqt để tính ma trận CQT, lấy giá trị magnitude.\n",
        "      - (Tùy chọn) Áp dụng log scaling để giảm phạm vi giá trị.\n",
        "      - Trung bình theo trục thời gian (axis=1) để thu được vector đặc trưng có kích thước (n_bins,).\n",
        "      \n",
        "    Nếu fmin không được chỉ định, librosa sẽ tự động sử dụng fmin mặc định.\n",
        "    \"\"\"\n",
        "    cqt_matrix = np.abs(librosa.cqt(signal_in, sr=sample_rate, hop_length=hop_length,\n",
        "                                    fmin=fmin, n_bins=n_bins, bins_per_octave=bins_per_octave))\n",
        "    if apply_log:\n",
        "        cqt_matrix = np.log(cqt_matrix + 1e-8)\n",
        "    # Trung bình theo trục thời gian (tính trung bình các cột)\n",
        "    features = np.mean(cqt_matrix, axis=1)\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n",
            "CQT extraction time: 414.43 seconds\n",
            "Extracting val data...\n",
            "CQT extraction time: 80.55 seconds\n",
            "Extracting test data...\n",
            "CQT extraction time: 165.68 seconds\n"
          ]
        }
      ],
      "source": [
        "def load_cqt_features_from_directory(directory, sample_rate=22050, hop_length=512, \n",
        "                                     fmin=None, n_bins=84, bins_per_octave=12, output_dir=None, dataset_type='train'):\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'cqt_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'cqt_labels_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "        \n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "                \n",
        "                # Compute CQT features\n",
        "                cqt_feature = compute_cqt_features(signal, sr, hop_length=hop_length, \n",
        "                                                   fmin=fmin, n_bins=n_bins, bins_per_octave=bins_per_octave, \n",
        "                                                   apply_log=True)\n",
        "                \n",
        "                features.append(cqt_feature)\n",
        "                labels.append(label)\n",
        "\n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        \n",
        "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
        "        if output_dir:\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"CQT extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels\n",
        "\n",
        "train_features_cqt, train_labels_cqt = load_cqt_features_from_directory(train_path, sample_rate=22050,\n",
        "                                                                        hop_length=512, fmin=None, n_bins=84, bins_per_octave=12, \n",
        "                                                                        output_dir=output_dir, dataset_type='train')\n",
        "val_features_cqt, val_labels_cqt = load_cqt_features_from_directory(val_path, sample_rate=22050,\n",
        "                                                                    hop_length=512, fmin=None, n_bins=84, bins_per_octave=12, \n",
        "                                                                    output_dir=output_dir, dataset_type='val')\n",
        "test_features_cqt, test_labels_cqt = load_cqt_features_from_directory(test_path, sample_rate=22050,\n",
        "                                                                      hop_length=512, fmin=None, n_bins=84, bins_per_octave=12, \n",
        "                                                                      output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_cqt = StandardScaler()\n",
        "train_features_cqt_scaled = scaler_cqt.fit_transform(train_features_cqt)\n",
        "val_features_cqt_scaled   = scaler_cqt.transform(val_features_cqt)\n",
        "test_features_cqt_scaled  = scaler_cqt.transform(test_features_cqt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CQT - KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.00 seconds\n",
            "KNN (CQT) - Test Accuracy: 85.25%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier_cqt = KNeighborsClassifier(n_neighbors=1, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "knn_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_cqt_knn = knn_classifier_cqt.predict(val_features_cqt_scaled)\n",
        "test_pred_cqt_knn = knn_classifier_cqt.predict(test_features_cqt_scaled)\n",
        "\n",
        "test_accuracy_cqt_knn = accuracy_score(test_labels_cqt, test_pred_cqt_knn)\n",
        "print(f\"KNN (CQT) - Test Accuracy: {test_accuracy_cqt_knn*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CQT - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 4.60 seconds\n",
            "SVM (CQT) - Test Accuracy: 85.11%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_classifier_cqt = SVC(C=100, kernel='rbf', gamma='auto', random_state=42)\n",
        "svm_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_cqt_svm = svm_classifier_cqt.predict(val_features_cqt_scaled)\n",
        "test_pred_cqt_svm = svm_classifier_cqt.predict(test_features_cqt_scaled)\n",
        "\n",
        "test_accuracy_cqt_svm = accuracy_score(test_labels_cqt, test_pred_cqt_svm)\n",
        "print(f\"SVM (CQT) - Test Accuracy: {test_accuracy_cqt_svm*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CQT - LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.89 seconds\n",
            "Logistic Regression (CQT) - Test Accuracy: 74.67%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "lr_classifier_cqt =LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, \n",
        "                                      fit_intercept=True, intercept_scaling=1, \n",
        "                                      class_weight=None, random_state=None, solver='lbfgs', \n",
        "                                      max_iter=500, multi_class='deprecated', verbose=0, \n",
        "                                      warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "lr_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_cqt_lr = lr_classifier_cqt.predict(val_features_cqt_scaled)\n",
        "test_pred_cqt_lr = lr_classifier_cqt.predict(test_features_cqt_scaled)\n",
        "\n",
        "test_accuracy_cqt_lr = accuracy_score(test_labels_cqt, test_pred_cqt_lr)\n",
        "print(f\"Logistic Regression (CQT) - Test Accuracy: {test_accuracy_cqt_lr*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CQT - RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 22.84 seconds\n",
            "Random Forest (CQT) - Test Accuracy: 86.45%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier_cqt = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
        "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
        "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "rf_classifier_cqt.fit(train_features_cqt, train_labels_cqt)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_cqt_rf = rf_classifier_cqt.predict(val_features_cqt)\n",
        "test_pred_cqt_rf = rf_classifier_cqt.predict(test_features_cqt)\n",
        "\n",
        "test_accuracy_cqt_rf = accuracy_score(test_labels_cqt, test_pred_cqt_rf)\n",
        "print(f\"Random Forest (CQT) - Test Accuracy: {test_accuracy_cqt_rf*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CQT - ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 23.36 seconds\n",
            "Extra Trees (CQT) - Test Accuracy: 86.59%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "et_classifier_cqt = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "et_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_cqt_et = et_classifier_cqt.predict(val_features_cqt_scaled)\n",
        "test_pred_cqt_et = et_classifier_cqt.predict(test_features_cqt_scaled)\n",
        "\n",
        "test_accuracy_cqt_et = accuracy_score(test_labels_cqt, test_pred_cqt_et)\n",
        "print(f\"Extra Trees (CQT) - Test Accuracy: {test_accuracy_cqt_et*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chroma + Spectral centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_chroma_and_centroid_features(signal_in, sample_rate, n_fft=2048, hop_length=512, n_chroma=12):\n",
        "    \"\"\"\n",
        "    Tính cả đặc trưng Chroma và Spectral Centroid của tín hiệu:\n",
        "      - Sử dụng librosa.feature.chroma_stft để tính ma trận chroma.\n",
        "      - Sử dụng librosa.feature.spectral_centroid để tính Spectral Centroid.\n",
        "      - Trung bình theo trục thời gian (axis=1) để thu được vector đặc trưng cho Chroma.\n",
        "      - Trung bình theo trục thời gian (axis=1) để thu được vector đặc trưng cho Spectral Centroid.\n",
        "      - Trả về vector đặc trưng kết hợp (chroma + centroid).\n",
        "    \"\"\"\n",
        "    # Tính đặc trưng Chroma\n",
        "    chroma = librosa.feature.chroma_stft(y=signal_in, sr=sample_rate, n_fft=n_fft, \n",
        "                                           hop_length=hop_length, n_chroma=n_chroma)\n",
        "    chroma_feature = np.mean(chroma, axis=1)\n",
        "\n",
        "    # Tính Spectral Centroid\n",
        "    centroid = librosa.feature.spectral_centroid(y=signal_in, sr=sample_rate, n_fft=n_fft, \n",
        "                                                 hop_length=hop_length)\n",
        "    centroid_feature = np.mean(centroid, axis=1)\n",
        "\n",
        "    # Kết hợp các đặc trưng vào một vector duy nhất\n",
        "    combined_feature = np.concatenate((chroma_feature, centroid_feature), axis=0)\n",
        "    return combined_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dinhg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
            "  return pitch_tuning(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined features extraction time: 245.02 seconds\n",
            "Extracting val data...\n",
            "Combined features extraction time: 21.94 seconds\n",
            "Extracting test data...\n",
            "Combined features extraction time: 43.72 seconds\n"
          ]
        }
      ],
      "source": [
        "def load_combined_features_from_directory(directory, sample_rate=22050, n_fft=2048, hop_length=512, n_chroma=12, output_dir=None, dataset_type='train'):\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'combined_features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'combined_labels_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "\n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "                \n",
        "                # Tính toán các đặc trưng kết hợp (chroma + centroid)\n",
        "                combined_feature = compute_chroma_and_centroid_features(signal, sr, n_fft=n_fft, \n",
        "                                                                        hop_length=hop_length, n_chroma=n_chroma)\n",
        "                \n",
        "                features.append(combined_feature)\n",
        "                labels.append(label)\n",
        "\n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        \n",
        "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
        "        if output_dir:\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"Combined features extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels\n",
        "\n",
        "train_features_combined, train_labels_combined = load_combined_features_from_directory(train_path, sample_rate=22050, n_fft=2048, hop_length=512, n_chroma=12, output_dir=output_dir, dataset_type='train')\n",
        "val_features_combined, val_labels_combined = load_combined_features_from_directory(val_path, sample_rate=22050, n_fft=2048, hop_length=512, n_chroma=12, output_dir=output_dir, dataset_type='val')\n",
        "test_features_combined, test_labels_combined = load_combined_features_from_directory(test_path, sample_rate=22050, n_fft=2048, hop_length=512, n_chroma=12, output_dir=output_dir, dataset_type='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_combined = StandardScaler()\n",
        "train_features_combined_scaled = scaler_combined.fit_transform(train_features_combined)\n",
        "val_features_combined_scaled   = scaler_combined.transform(val_features_combined)\n",
        "test_features_combined_scaled  = scaler_combined.transform(test_features_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chroma + SC - KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.03 seconds\n",
            "KNN (combined) - Test Accuracy: 73.19%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier_combined = KNeighborsClassifier(n_neighbors=9, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "knn_classifier_combined.fit(train_features_combined_scaled, train_labels_combined)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_combined_knn = knn_classifier_combined.predict(val_features_combined_scaled)\n",
        "test_pred_combined_knn = knn_classifier_combined.predict(test_features_combined_scaled)\n",
        "\n",
        "test_accuracy_combined_knn = accuracy_score(test_labels_combined, test_pred_combined_knn)\n",
        "print(f\"KNN (combined) - Test Accuracy: {test_accuracy_combined_knn*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chroma + SC - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 6.18 seconds\n",
            "SVM (combined) - Test Accuracy: 77.10%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_classifier_combined = SVC(C=50, kernel='rbf', gamma='auto', random_state=42)\n",
        "svm_classifier_combined.fit(train_features_combined_scaled, train_labels_combined)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_combined_svm = svm_classifier_combined.predict(val_features_combined_scaled)\n",
        "test_pred_combined_svm = svm_classifier_combined.predict(test_features_combined_scaled)\n",
        "\n",
        "test_accuracy_combined_svm = accuracy_score(test_labels_combined, test_pred_combined_svm)\n",
        "print(f\"SVM (combined) - Test Accuracy: {test_accuracy_combined_svm*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chroma + SC - LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.11 seconds\n",
            "Logistic Regression (combined) - Test Accuracy: 54.35%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "lr_classifier_combined =LogisticRegression(penalty='l2', dual=False, tol=0.001, C=1, \n",
        "                                      fit_intercept=True, intercept_scaling=1, \n",
        "                                      class_weight=None, random_state=None, solver='lbfgs', \n",
        "                                      max_iter=500, multi_class='deprecated', verbose=0, \n",
        "                                      warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "lr_classifier_combined.fit(train_features_combined_scaled, train_labels_combined)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_combined_lr = lr_classifier_combined.predict(val_features_combined_scaled)\n",
        "test_pred_combined_lr = lr_classifier_combined.predict(test_features_combined_scaled)\n",
        "\n",
        "test_accuracy_combined_lr = accuracy_score(test_labels_combined, test_pred_combined_lr)\n",
        "print(f\"Logistic Regression (combined) - Test Accuracy: {test_accuracy_combined_lr*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chroma + SC - RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 7.56 seconds\n",
            "Random Forest (combined) - Test Accuracy: 75.83%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "rf_classifier_combined = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
        "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
        "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "rf_classifier_combined.fit(train_features_combined, train_labels_combined)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_combined_rf = rf_classifier_combined.predict(val_features_combined)\n",
        "test_pred_combined_rf = rf_classifier_combined.predict(test_features_combined)\n",
        "\n",
        "test_accuracy_combined_rf = accuracy_score(test_labels_combined, test_pred_combined_rf)\n",
        "print(f\"Random Forest (combined) - Test Accuracy: {test_accuracy_combined_rf*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chroma + SC - ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 8.56 seconds\n",
            "Extra Trees (combined) - Test Accuracy: 76.34%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "et_classifier_combined = ExtraTreesClassifier(n_estimators=300, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
        "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
        "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
        "\n",
        "et_classifier_combined.fit(train_features_combined_scaled, train_labels_combined)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_combined_et = et_classifier_combined.predict(val_features_combined_scaled)\n",
        "test_pred_combined_et = et_classifier_combined.predict(test_features_combined_scaled)\n",
        "\n",
        "test_accuracy_combined_et = accuracy_score(test_labels_combined, test_pred_combined_et)\n",
        "print(f\"Extra Trees (combined) - Test Accuracy: {test_accuracy_combined_et*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_chroma_energy(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
        "    stft = librosa.stft(signal_in, n_fft=int(frame_size * sample_rate), hop_length=int(frame_stride * sample_rate))\n",
        "    chroma = librosa.feature.chroma_stft(S=np.abs(stft), sr=sample_rate)\n",
        "    chroma_energy = np.sum(chroma**2, axis=1)\n",
        "    return chroma_energy\n",
        "\n",
        "def compute_rmse(signal_in, sample_rate=22050, frame_size=0.025, frame_stride=0.01):\n",
        "    rmse = librosa.feature.rms(y=signal_in)\n",
        "    return rmse[0]\n",
        "\n",
        "def compute_zcr(signal_in, sample_rate=22050, frame_size=0.025, frame_stride=0.01):\n",
        "    zcr = librosa.feature.zero_crossing_rate(signal_in, frame_length=int(frame_size * sample_rate), hop_length=int(frame_stride * sample_rate))\n",
        "    return zcr[0]\n",
        "\n",
        "def compute_spectral_flux(signal_in, sample_rate=22050, frame_size=0.025, frame_stride=0.01):\n",
        "    stft = librosa.stft(signal_in, n_fft=int(frame_size * sample_rate), hop_length=int(frame_stride * sample_rate))\n",
        "    mag_frames = np.abs(stft)\n",
        "    flux = np.diff(mag_frames, axis=1)\n",
        "    spectral_flux = np.sum(flux, axis=0)\n",
        "    return spectral_flux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting train data...\n",
            "Feature extraction time: 190.46 seconds\n",
            "Extracting val data...\n",
            "Feature extraction time: 27.02 seconds\n",
            "Extracting test data...\n",
            "Feature extraction time: 56.55 seconds\n"
          ]
        }
      ],
      "source": [
        "def extract_features(directory, sample_rate=22050, output_dir=None, dataset_type='train'):\n",
        "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
        "    features_file = os.path.join(output_dir, f'features_{dataset_type}.pkl')\n",
        "    labels_file = os.path.join(output_dir, f'labels_{dataset_type}.pkl')\n",
        "    data_file = os.path.join(output_dir, f'data_{dataset_type}.pkl')\n",
        "    \n",
        "    if os.path.exists(features_file) and os.path.exists(labels_file) and os.path.exists(data_file):\n",
        "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
        "        features = joblib.load(features_file)\n",
        "        labels = joblib.load(labels_file)\n",
        "        data = joblib.load(data_file)\n",
        "    else:\n",
        "        print(f\"Extracting {dataset_type} data...\")\n",
        "        start_time = time.time()\n",
        "        labels = []\n",
        "        features = []\n",
        "        data = []  # Thêm một biến để lưu dữ liệu đầu vào (có thể là tín hiệu, ví dụ như signal hoặc các thông tin khác)\n",
        "        \n",
        "        for label in ['bee', 'nobee', 'noqueen']:\n",
        "            path = os.path.join(directory, label)\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
        "                \n",
        "                # Tính toán các đặc trưng\n",
        "                chroma_energy = compute_chroma_energy(signal, sr)\n",
        "                rmse = compute_rmse(signal, sr)\n",
        "                zcr = compute_zcr(signal, sr)\n",
        "                spectral_flux = compute_spectral_flux(signal, sr)\n",
        "                \n",
        "                # Tính trung bình các đặc trưng nếu cần\n",
        "                feature = np.hstack([chroma_energy, rmse, zcr, spectral_flux])\n",
        "                \n",
        "                features.append(feature)\n",
        "                labels.append(label)\n",
        "                data.append(signal)  # Lưu tín hiệu âm thanh gốc hoặc dữ liệu khác nếu cần\n",
        "        \n",
        "        features = np.array(features)\n",
        "        labels = np.array(labels)\n",
        "        data = np.array(data)  # Chuyển dữ liệu sang dạng numpy array nếu cần lưu\n",
        "        \n",
        "        if output_dir:\n",
        "            # Lưu từng đối tượng riêng biệt cho train/val/test\n",
        "            joblib.dump(features, features_file)\n",
        "            joblib.dump(labels, labels_file)\n",
        "            joblib.dump(data, data_file)  # Lưu tín hiệu âm thanh hoặc dữ liệu\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"Feature extraction time: {end_time - start_time:.2f} seconds\")\n",
        "    \n",
        "    return features, labels, data\n",
        "\n",
        "train_features, train_labels, train_data = extract_features(train_path, output_dir=output_dir, dataset_type='train')\n",
        "val_features, val_labels, val_data = extract_features(val_path, output_dir=output_dir, dataset_type='val')\n",
        "test_features, test_labels, test_data = extract_features(test_path, output_dir=output_dir, dataset_type='test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_cafe = StandardScaler()\n",
        "train_features_cafe_scaled = scaler_cafe.fit_transform(train_features)\n",
        "val_features_cafe_scaled   = scaler_cafe.transform(val_features)\n",
        "test_features_cafe_scaled  = scaler_cafe.transform(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 0.02 seconds\n",
            "KNN (cafe) - Test Accuracy: 53.51%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "knn_classifier_cafe = KNeighborsClassifier(n_neighbors=13, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
        "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
        "\n",
        "knn_classifier_cafe.fit(train_features_cafe_scaled, train_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_cafe_knn = knn_classifier_cafe.predict(val_features_cafe_scaled)\n",
        "test_pred_cafe_knn = knn_classifier_cafe.predict(test_features_cafe_scaled)\n",
        "\n",
        "test_accuracy_cafe_knn = accuracy_score(test_labels, test_pred_cafe_knn)\n",
        "print(f\"KNN (cafe) - Test Accuracy: {test_accuracy_cafe_knn*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 34.42 seconds\n",
            "SVM (cafe) - Test Accuracy: 70.14%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "svm_classifier_cafe = SVC(C=10, kernel='rbf', gamma='auto', random_state=42)\n",
        "svm_classifier_cafe.fit(train_features_cafe_scaled, train_labels)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "val_pred_cafe_svm = svm_classifier_cafe.predict(val_features_cafe_scaled)\n",
        "test_pred_cafe_svm = svm_classifier_cafe.predict(test_features_cafe_scaled)\n",
        "\n",
        "test_accuracy_cafe_svm = accuracy_score(test_labels, test_pred_cafe_svm)\n",
        "print(f\"SVM (cafe) - Test Accuracy: {test_accuracy_cafe_svm*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
