{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "import librosa.display\n",
    "import scipy.fftpack as fftpack\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'E:/Queenless/20k_audio_splitted_dataset/train'\n",
    "val_path = 'E:/Queenless/20k_audio_splitted_dataset/val'\n",
    "test_path = 'E:/Queenless/20k_audio_splitted_dataset/test'\n",
    "\n",
    "output_dir = 'E:/Queenless/features'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis(signal_in, alpha=0.97):\n",
    "    \"\"\"\n",
    "    Bước 1: Pre-emphasis - Lọc thông cao\n",
    "    \"\"\"\n",
    "    emphasized_signal = np.append(signal_in[0], signal_in[1:] - alpha * signal_in[:-1]) # y(t) = x(t) - alpha*x(t-1)\n",
    "    return emphasized_signal\n",
    "\n",
    "def framing(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
    "    \"\"\"\n",
    "    Bước 2: Chia khung (Framing)\n",
    "    - frame_size: kích thước khung (số giây)\n",
    "    - frame_stride: bước nhảy giữa các khung (số giây)\n",
    "    \"\"\"\n",
    "    frame_length = int(round(frame_size * sample_rate))\n",
    "    frame_step = int(round(frame_stride * sample_rate))\n",
    "    signal_length = len(signal_in)\n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step)) + 1\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    # Zero-padding nếu cần\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(signal_in, z)\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    return frames\n",
    "\n",
    "def windowing(frames):\n",
    "    \"\"\"\n",
    "    Bước 3: Áp dụng cửa sổ Hamming cho mỗi khung\n",
    "    \"\"\"\n",
    "    frame_length = frames.shape[1]\n",
    "    hamming = np.hamming(frame_length)\n",
    "    windowed_frames = frames * hamming\n",
    "    return windowed_frames\n",
    "\n",
    "def fft_frames(frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Bước 4: Tính FFT cho mỗi khung\n",
    "    \"\"\"\n",
    "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))\n",
    "    return mag_frames\n",
    "\n",
    "def power_spectrum(mag_frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Bước 4.1: Tính phổ công suất của mỗi khung\n",
    "    \"\"\"\n",
    "    return (1.0 / NFFT) * (mag_frames ** 2)\n",
    "\n",
    "def mel_filterbank(sample_rate, NFFT, nfilt=26, low_freq=0, high_freq=None):\n",
    "    \"\"\"\n",
    "    Bước 5: Tạo Mel filterbank\n",
    "    \"\"\"\n",
    "    if high_freq is None:\n",
    "        high_freq = sample_rate / 2\n",
    "\n",
    "    # Chuyển Hz sang Mel\n",
    "    low_mel = 2595 * np.log10(1 + low_freq / 700.0)\n",
    "    high_mel = 2595 * np.log10(1 + high_freq / 700.0)\n",
    "    mel_points = np.linspace(low_mel, high_mel, nfilt + 2)\n",
    "    # Chuyển lại từ Mel sang Hz\n",
    "    hz_points = 700 * (10**(mel_points / 2595) - 1)\n",
    "    bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "\n",
    "    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, nfilt + 1):\n",
    "        f_m_minus = int(bin[m - 1])   # giới hạn trái\n",
    "        f_m = int(bin[m])             # trung tâm\n",
    "        f_m_plus = int(bin[m + 1])    # giới hạn phải\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    return fbank\n",
    "\n",
    "# Hàm tính mfccs\n",
    "def compute_mfccs(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, \n",
    "                 pre_emph=0.97, NFFT=512, nfilt=26, num_ceps=13):\n",
    "    emphasized_signal = pre_emphasis(signal_in, pre_emph)\n",
    "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
    "    windowed_frames = windowing(frames)\n",
    "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
    "    pow_frames = power_spectrum(mag_frames, NFFT)\n",
    "    fbank = mel_filterbank(sample_rate, NFFT, nfilt)\n",
    "    filter_banks = np.dot(pow_frames, fbank.T)\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
    "    log_fbank = np.log(filter_banks)\n",
    "    mfccs = fftpack.dct(log_fbank, type=2, axis=1, norm='ortho')[:, :num_ceps]\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from .pkl files...\n",
      "Loading val data from .pkl files...\n",
      "Loading test data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_mfccs_features(directory, sample_rate=22050, output_dir=None, dataset_type='train'):\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    features_file = os.path.join(output_dir, f'mfccs_features_{dataset_type}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'mfccs_labels_{dataset_type}.pkl')\n",
    "    data_file = os.path.join(output_dir, f'mfccs_data_{dataset_type}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file) and os.path.exists(data_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "        data = joblib.load(data_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        data = []  # Thêm một biến để lưu dữ liệu đầu vào (có thể là tín hiệu, ví dụ như signal hoặc các thông tin khác)\n",
    "        \n",
    "        for label in ['Queen', 'NonQueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            for file in os.listdir(path):\n",
    "                file_path = os.path.join(path, file)\n",
    "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                mfccs = compute_mfccs(signal_in=signal, sample_rate=sr)\n",
    "                mfccs_mean = np.mean(mfccs, axis=0)\n",
    "                features.append(mfccs_mean)\n",
    "                labels.append(label)\n",
    "                data.append(signal)  # Lưu tín hiệu âm thanh gốc hoặc dữ liệu khác nếu cần\n",
    "        \n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        data = np.array(data)  # Chuyển dữ liệu sang dạng numpy array nếu cần lưu\n",
    "        \n",
    "        if output_dir:\n",
    "            # Lưu từng đối tượng riêng biệt cho train/val/test\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "            joblib.dump(data, data_file)  # Lưu tín hiệu âm thanh hoặc dữ liệu\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"MFCCs extraction time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return features, labels, data\n",
    "\n",
    "train_features_mfccs, train_labels_mfccs, train_data_mfccs = extract_mfccs_features(train_path, output_dir=output_dir, dataset_type='train')\n",
    "val_features_mfccs, val_labels_mfccs, val_data_mfccs = extract_mfccs_features(val_path, output_dir=output_dir, dataset_type='val')\n",
    "test_features_mfccs, test_labels_mfccs, test_data_mfccs = extract_mfccs_features(test_path, output_dir=output_dir, dataset_type='test')\n",
    "train_features_mfccs = np.vstack((train_features_mfccs, val_features_mfccs))\n",
    "train_labels_mfccs = np.hstack((train_labels_mfccs, val_labels_mfccs))\n",
    "train_data_mfccs = np.vstack((train_data_mfccs, val_data_mfccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16076, 13)\n",
      "(4000, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_features_mfccs.shape)\n",
    "print(test_features_mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-84.59486884,   6.34044745,  -2.47652946,   5.6866161 ,\n",
       "        -6.0883983 ,   3.79775816,  -4.57106924,   2.68850088,\n",
       "        -2.55462216,   1.96805757,  -1.50288011,   0.65516511,\n",
       "        -0.11471445])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_mfccs[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_mfccs_scaled = scaler.fit_transform(train_features_mfccs)\n",
    "test_features_mfccs_scaled = scaler.transform(test_features_mfccs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 11.29 seconds\n",
      "Test Accuracy: 92.42%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
    "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "rf_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_predictions = rf_classifier.predict(test_features_mfccs_scaled)\n",
    "test_accuracy_mfccs_rf = accuracy_score(test_labels_mfccs, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy_mfccs_rf * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning bootstrap=False from 92% to 92.38%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 13.13 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 94.10%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=10, kernel='rbf', degree=3, gamma=1, coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_mfccs)\n",
    "test_accuracy_mfccs_svm = accuracy_score(test_labels_mfccs, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_mfccs_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 31.61 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 94.27%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Khởi tạo mô hình SVM với data scaling\n",
    "svm_rbf_classifier = SVC(C=10, kernel='rbf', degree=3, gamma=1, coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_mfccs_scaled)\n",
    "scale_test_accuracy_mfccs_svm = accuracy_score(test_labels_mfccs, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_mfccs_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data improve from 94% to 94.05%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.09 seconds\n",
      "Test Accuracy (Logistic Regression): 72.60%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Khởi tạo mô hình Logistic Regression\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='liblinear', max_iter=100, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "# Huấn luyện mô hình Logistic Regression với dữ liệu đã chuẩn hóa\n",
    "lr_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_lr = lr_classifier.predict(test_features_mfccs)\n",
    "test_accuracy_mfccs_lr = accuracy_score(test_labels_mfccs, test_predictions_lr)\n",
    "print(f\"Test Accuracy (Logistic Regression): {test_accuracy_mfccs_lr * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.04 seconds\n",
      "Test Accuracy (Logistic Regression): 73.22%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Khởi tạo mô hình Logistic Regression với data scaling\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='liblinear', max_iter=100, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "# Huấn luyện mô hình Logistic Regression với dữ liệu đã chuẩn hóa\n",
    "lr_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_lr = lr_classifier.predict(test_features_mfccs_scaled)\n",
    "scale_test_accuracy_mfccs_lr = accuracy_score(test_labels_mfccs, test_predictions_lr)\n",
    "print(f\"Test Accuracy (Logistic Regression): {scale_test_accuracy_mfccs_lr * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned the LR model but still only has 73.28% accuracy -> problem with feature extraction method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs - ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 7.14 seconds\n",
      "Test Accuracy (Extra Trees): 92.97%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Khởi tạo mô hình Extra Trees \n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "et_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_mfccs)\n",
    "test_accuracy_mfccs_et = accuracy_score(test_labels_mfccs, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {test_accuracy_mfccs_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 7.18 seconds\n",
      "Test Accuracy (Extra Trees): 92.95%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Khởi tạo mô hình Extra Trees với data scaling\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_mfccs_scaled)\n",
    "scale_test_accuracy_mfccs_et = accuracy_score(test_labels_mfccs, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_mfccs_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tuning improved from 92.53% to 92.97%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.07 seconds\n",
      "Test Accuracy (KNN): 91.77%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "# Huấn luyện mô hình KNN với dữ liệu đã chuẩn hóa\n",
    "knn_classifier.fit(train_features_mfccs, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_knn = knn_classifier.predict(test_features_mfccs)\n",
    "test_accuracy_mfccs_knn = accuracy_score(test_labels_mfccs, test_predictions_knn)\n",
    "print(f\"Test Accuracy (KNN): {test_accuracy_mfccs_knn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.04 seconds\n",
      "Test Accuracy (KNN): 92.95%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "# Huấn luyện mô hình KNN với dữ liệu đã chuẩn hóa\n",
    "knn_classifier.fit(train_features_mfccs_scaled, train_labels_mfccs)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_knn = knn_classifier.predict(test_features_mfccs_scaled)\n",
    "scale_test_accuracy_mfccs_knn = accuracy_score(test_labels_mfccs, test_predictions_knn)\n",
    "print(f\"Test Accuracy (KNN): {scale_test_accuracy_mfccs_knn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFTs (with pre-emphasis, framing, windowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis(signal_in, pre_emph=0.97):\n",
    "    \"\"\"\n",
    "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
    "    \"\"\"\n",
    "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
    "\n",
    "def framing(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
    "    \"\"\"\n",
    "    Chia tín hiệu thành các frame có kích thước và bước nhảy xác định.\n",
    "    \"\"\"\n",
    "    frame_length = int(round(frame_size * sample_rate))\n",
    "    frame_step = int(round(frame_stride * sample_rate))\n",
    "    signal_length = len(signal_in)\n",
    "    num_frames = int(np.ceil(np.abs(signal_length - frame_length) / frame_step)) + 1\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(signal_in, z)\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    return frames\n",
    "\n",
    "def windowing(frames):\n",
    "    \"\"\"\n",
    "    Áp dụng cửa sổ Hamming cho mỗi frame.\n",
    "    \"\"\"\n",
    "    frame_length = frames.shape[1]\n",
    "    hamming = np.hamming(frame_length)\n",
    "    return frames * hamming\n",
    "\n",
    "def fft_frames(frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
    "    \"\"\"\n",
    "    return np.absolute(np.fft.rfft(frames, NFFT))\n",
    "\n",
    "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, NFFT=512, apply_log=True):\n",
    "    \"\"\"\n",
    "    Tính toán đặc trưng FFT cho tín hiệu âm thanh:\n",
    "      - Pre-emphasis, Framing, Windowing.\n",
    "      - Tính FFT cho từng frame và lấy giá trị magnitude.\n",
    "      - Trung bình các frame để có vector đặc trưng ổn định.\n",
    "      - (Tùy chọn) Áp dụng log để giảm phạm vi giá trị.\n",
    "      \n",
    "    Trả về: vector đặc trưng có kích thước (NFFT/2+1,).\n",
    "    \"\"\"\n",
    "    emphasized_signal = pre_emphasis(signal_in)\n",
    "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
    "    windowed_frames = windowing(frames)\n",
    "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
    "    fft_feature = np.mean(mag_frames, axis=0)  # Trung bình theo các frame\n",
    "    if apply_log:\n",
    "        fft_feature = np.log(fft_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
    "    return fft_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pre_emphasis(signal_in, pre_emph=0.97):\n",
    "    \"\"\"\n",
    "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
    "    \"\"\"\n",
    "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
    "\n",
    "def framing(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
    "    \"\"\"\n",
    "    Chia tín hiệu thành các frame có kích thước và bước nhảy xác định.\n",
    "    \"\"\"\n",
    "    frame_length = int(round(frame_size * sample_rate))\n",
    "    frame_step = int(round(frame_stride * sample_rate))\n",
    "    signal_length = len(signal_in)\n",
    "    \n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step)) + 1\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    pad_signal = np.pad(signal_in, (0, pad_signal_length - signal_length), mode='constant')\n",
    "\n",
    "    indices = np.arange(0, frame_length) + np.arange(0, num_frames * frame_step, frame_step)[:, None]\n",
    "    frames = pad_signal[indices.astype(np.int32)]\n",
    "    return frames\n",
    "\n",
    "def windowing(frames):\n",
    "    \"\"\"\n",
    "    Áp dụng cửa sổ Hamming cho mỗi frame.\n",
    "    \"\"\"\n",
    "    frame_length = frames.shape[1]\n",
    "    hamming = np.hamming(frame_length)\n",
    "    return frames * hamming\n",
    "\n",
    "def fft_frames(frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
    "    \"\"\"\n",
    "    return np.abs(np.fft.fft(frames, NFFT))[:, :NFFT//2+1]  # Chỉ lấy giá trị magnitude dương\n",
    "\n",
    "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, NFFT=512, apply_log=True):\n",
    "    \"\"\"\n",
    "    Tính toán đặc trưng FFT cho tín hiệu âm thanh:\n",
    "      - Pre-emphasis, Framing, Windowing.\n",
    "      - Tính FFT cho từng frame và lấy giá trị magnitude.\n",
    "      - Trung bình các frame để có vector đặc trưng ổn định.\n",
    "      - (Tùy chọn) Áp dụng log để giảm phạm vi giá trị.\n",
    "    Trả về: vector đặc trưng có kích thước (NFFT/2+1,).\n",
    "    \"\"\"\n",
    "    emphasized_signal = pre_emphasis(signal_in)\n",
    "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
    "    windowed_frames = windowing(frames)\n",
    "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
    "    fft_feature = np.mean(mag_frames, axis=0)  # Trung bình theo các frame\n",
    "    \n",
    "    # Áp dụng log nếu cần, đảm bảo không có log(0)\n",
    "    if apply_log:\n",
    "        fft_feature = np.log(np.maximum(fft_feature, 1e-8))  # Thêm epsilon để tránh log(0)\n",
    "    \n",
    "    return fft_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fft_features_from_directory(directory, sample_rate=22050, NFFT=512, output_dir=None, dataset_type='train'):\n",
    "    \"\"\"\n",
    "    Duyệt qua các file âm thanh trong thư mục và tính đặc trưng FFT cho mỗi file.\n",
    "    Giả sử trong directory có hai thư mục con: 'Queen' và 'NonQueen'.\n",
    "    \n",
    "    Trả về:\n",
    "      - features: mảng đặc trưng (mỗi đặc trưng có kích thước NFFT/2+1)\n",
    "      - labels: nhãn tương ứng.\n",
    "    \"\"\"\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    features_file = os.path.join(output_dir, f'fft3_features_{dataset_type}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'fft3_labels_{dataset_type}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        \n",
    "        for label in ['Queen', 'NonQueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            for file in os.listdir(path):\n",
    "                file_path = os.path.join(path, file)\n",
    "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                fft_feature = compute_fft_features(signal, sr, NFFT=NFFT)\n",
    "                features.append(fft_feature)\n",
    "                labels.append(label)\n",
    "        \n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
    "        if output_dir:\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"FFT extraction time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from .pkl files...\n",
      "Loading val data from .pkl files...\n",
      "Loading test data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "train_features_fft, train_labels_fft = load_fft_features_from_directory(train_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='train')\n",
    "val_features_fft, val_labels_fft = load_fft_features_from_directory(val_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='val')\n",
    "test_features_fft, test_labels_fft = load_fft_features_from_directory(test_path, sample_rate=22050, NFFT=512, output_dir=output_dir, dataset_type='test')\n",
    "\n",
    "train_features_fft = np.vstack((train_features_fft, val_features_fft))\n",
    "train_labels_fft = np.hstack((train_labels_fft, val_labels_fft))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_fft_scaled = scaler.fit_transform(train_features_fft)\n",
    "test_features_fft_scaled = scaler.transform(test_features_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFTs - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.01 seconds\n",
      "KNN (FFT features) - Test Accuracy: 95.53%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft)\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "94.25% to 95.15%, pre_emph = 0.98 => 95.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.01 seconds\n",
      "KNN (FFT features) - Test Accuracy: 94.65%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_fft_knn = knn_classifier.predict(test_features_fft_scaled)\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "94.25%, pre_emph = 0.98 => 94.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFTs - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 15.34 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 97.60%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_fft_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97.47%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 62.01 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 97.82%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_fft_scaled)\n",
    "scale_test_accuracy_fft_svm = accuracy_score(test_labels_fft, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_fft_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFTs - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3.07 seconds\n",
      "Logistic Regression (FFT features) - Test Accuracy: 86.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinhg\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='lbfgs', max_iter=1500, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "lr_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_fft_lr = lr_classifier.predict(test_features_fft)\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_lr)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 69.04 seconds\n",
      "Logistic Regression (FFT features) - Test Accuracy: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinhg\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='saga', max_iter=1000, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "lr_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "scale_test_accuracy_fft_lr = lr_classifier.predict(test_features_fft_scaled)\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, scale_test_accuracy_fft_lr)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning from 85.97% to 86.05%\n",
    "\n",
    "Using min max scaling -> 86.08%\n",
    "\n",
    "But Non-scaling data working better -> 86.33%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFTs - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 37.20 seconds\n",
      "Random Forest (FFT features) - Test Accuracy: 94.62%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                       max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                                       n_jobs=None, random_state=42, verbose=0, warm_start=False, class_weight=None, \n",
    "                                       ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "rf_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_fft_rf = rf_classifier.predict(test_features_fft)\n",
    "print(f\"Random Forest (FFT features) - Test Accuracy: {accuracy_score(test_labels_fft, test_accuracy_fft_rf)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not tuning yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFTs - ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 124.75 seconds\n",
      "Test Accuracy (Extra Trees): 96.00%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "et_classifier.fit(train_features_fft, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_fft)\n",
    "test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {test_accuracy_fft_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 128.48 seconds\n",
      "Test Accuracy (Extra Trees): 95.97%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_fft_scaled, train_labels_fft)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_fft_scaled)\n",
    "scale_test_accuracy_fft_et = accuracy_score(test_labels_fft, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_fft_et * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93.95% -> 95.80% beautifull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC (lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(file_path, n_mfcc=13):\n",
    "    y, sr = librosa.load(file_path, sr=16000) \n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, S=None, n_mfcc=n_mfcc, dct_type=2, norm='ortho', lifter=0)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train data...\n",
      "MFCC extraction time: 271.60 seconds\n",
      "Extracting val data...\n",
      "MFCC extraction time: 36.73 seconds\n",
      "Extracting test data...\n",
      "MFCC extraction time: 73.64 seconds\n"
     ]
    }
   ],
   "source": [
    "def extract_mfcc_features(directory, sample_rate=22050, output_dir=None, dataset_type='train', reduce_dimension=True):\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    features_file = os.path.join(output_dir, f'mfcc2_features_{dataset_type}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'mfcc2_labels_{dataset_type}.pkl')\n",
    "    data_file = os.path.join(output_dir, f'mfcc2_data_{dataset_type}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file) and os.path.exists(data_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "        data = joblib.load(data_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        data = []  # Thêm một biến để lưu dữ liệu đầu vào (có thể là tín hiệu, ví dụ như signal hoặc các thông tin khác)\n",
    "        \n",
    "        for label in ['Queen', 'NonQueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            for file in os.listdir(path):\n",
    "                file_path = os.path.join(path, file)\n",
    "                mfcc = compute_mfcc(file_path=file_path, n_mfcc=70)  # Chiết xuất MFCC cho mỗi tệp âm thanh\n",
    "                features.append(mfcc)  # Lưu ma trận MFCC cho mỗi tệp âm thanh\n",
    "                labels.append(label)\n",
    "        \n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        data = np.array(data)  # Chuyển dữ liệu sang dạng numpy array nếu cần lưu\n",
    "        \n",
    "        # Nếu cần giảm chiều theo axis=2\n",
    "        if reduce_dimension:\n",
    "            features = np.mean(features, axis=2)\n",
    "        \n",
    "        if output_dir:\n",
    "            # Lưu từng đối tượng riêng biệt cho train/val/test\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "            joblib.dump(data, data_file)  # Lưu tín hiệu âm thanh hoặc dữ liệu\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"MFCC extraction time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return features, labels, data\n",
    "\n",
    "# Gọi hàm với tham số reduce_dimension=True để giảm chiều ngay khi gọi hàm\n",
    "train_features_mfcc, train_labels_mfcc, train_data_mfcc = extract_mfcc_features(train_path, output_dir=output_dir, dataset_type='train')\n",
    "val_features_mfcc, val_labels_mfcc, val_data_mfcc = extract_mfcc_features(val_path, output_dir=output_dir, dataset_type='val')\n",
    "test_features_mfcc, test_labels_mfcc, test_data_mfcc = extract_mfcc_features(test_path, output_dir=output_dir, dataset_type='test')\n",
    "train_features_mfcc = np.vstack((train_features_mfcc, val_features_mfcc))\n",
    "train_labels_mfcc = np.hstack((train_labels_mfcc, val_labels_mfcc))    \n",
    "train_data_mfcc = np.vstack((train_data_mfcc, val_data_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16076, 70)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_mfcc_scaled = scaler.fit_transform(train_features_mfcc)\n",
    "test_features_mfcc_scaled = scaler.transform(test_features_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 6.94 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 98.38%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=8.31, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_mfcc_scaled, train_labels_mfcc)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_mfcc_scaled)\n",
    "scale_test_accuracy_mfcc_svm = accuracy_score(test_labels_mfcc, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_mfcc_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98.55%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "def apply_preprocessing(signal_in, sample_rate):\n",
    "    \"\"\"\n",
    "    Apply optional preprocessing steps on the signal:\n",
    "      - Apply pre-emphasis filtering.\n",
    "    \"\"\"\n",
    "    # Pre-emphasis filter: Boosting higher frequencies slightly\n",
    "    pre_emphasis = 0.97\n",
    "    signal_in = np.append(signal_in[0], signal_in[1:] - pre_emphasis * signal_in[:-1])\n",
    "    return signal_in\n",
    "\n",
    "def frame_signal(signal, frame_size, hop_length):\n",
    "    \"\"\"\n",
    "    Convert a signal into overlapping frames.\n",
    "    \n",
    "    Args:\n",
    "        signal: Input audio signal\n",
    "        frame_size: Number of samples per frame\n",
    "        hop_length: Number of samples between frames\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Framed signal of shape (frame_length, num_frames)\n",
    "    \"\"\"\n",
    "    # Calculate the number of frames\n",
    "    num_frames = 1 + int((len(signal) - frame_size) / hop_length)\n",
    "    \n",
    "    # Create an empty array to store frames\n",
    "    frames = np.zeros((frame_size, num_frames))\n",
    "    \n",
    "    # Frame the signal\n",
    "    for i in range(num_frames):\n",
    "        start = i * hop_length\n",
    "        end = start + frame_size\n",
    "        if end <= len(signal):\n",
    "            frames[:, i] = signal[start:end]\n",
    "        else:  # Zero padding for last frame if needed\n",
    "            frames[:len(signal)-start, i] = signal[start:]\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def apply_window(frames, window_type='hann'):\n",
    "    \"\"\"\n",
    "    Apply a window function to each frame.\n",
    "    \n",
    "    Args:\n",
    "        frames: Framed signal of shape (frame_length, num_frames)\n",
    "        window_type: Type of window function ('hann', 'hamming', 'blackman', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Windowed frames\n",
    "    \"\"\"\n",
    "    # Create the window function\n",
    "    frame_length = frames.shape[0]\n",
    "    window = np.zeros(frame_length)\n",
    "    \n",
    "    if window_type == 'hann':\n",
    "        window = np.hanning(frame_length)\n",
    "    elif window_type == 'hamming':\n",
    "        window = np.hamming(frame_length)\n",
    "    elif window_type == 'blackman':\n",
    "        window = np.blackman(frame_length)\n",
    "    else:  # Default to Hann window\n",
    "        window = np.hanning(frame_length)\n",
    "    \n",
    "    # Apply window to each frame (element-wise multiplication)\n",
    "    return frames * window.reshape(-1, 1)\n",
    "\n",
    "def compute_stfts_features(signal_in, sample_rate, n_fft=2048, hop_length=512, \n",
    "                          window_type='hann', apply_log=True):\n",
    "    \"\"\"\n",
    "    Compute STFT features with explicitly separated steps:\n",
    "      - Apply preprocessing (pre-emphasis)\n",
    "      - Frame the signal into overlapping segments\n",
    "      - Apply windowing to each frame\n",
    "      - Compute STFT\n",
    "      - Extract features with optional log scaling\n",
    "    \"\"\"\n",
    "    # Apply preprocessing (e.g., pre-emphasis)\n",
    "    signal_in = apply_preprocessing(signal_in, sample_rate)\n",
    "    \n",
    "    # Explicit framing and windowing (for demonstration, though librosa.stft does this internally)\n",
    "    frames = frame_signal(signal_in, n_fft, hop_length)\n",
    "    windowed_frames = apply_window(frames, window_type)\n",
    "    \n",
    "    # Note: In practice, we could use these windowed frames directly for FFT\n",
    "    # but for compatibility with the original code, we'll use librosa.stft\n",
    "    \n",
    "    # Compute STFT with a window function to avoid spectral leakage\n",
    "    stfts_matrix = np.abs(librosa.stft(signal_in, n_fft=n_fft, hop_length=hop_length, window=window_type))\n",
    "    \n",
    "    # Optional: Apply logarithmic scaling (dynamic range compression)\n",
    "    if apply_log:\n",
    "        stfts_matrix = np.log(stfts_matrix + 1e-10)  # More robust epsilon for log scaling\n",
    "\n",
    "    # Feature extraction: Mean and additional energy-based features (e.g., variance)\n",
    "    features_mean = np.mean(stfts_matrix, axis=1)\n",
    "    features_variance = np.var(stfts_matrix, axis=1)\n",
    "    \n",
    "    # Combine mean and variance (you could also add other stats like median or skewness)\n",
    "    features = np.concatenate([features_mean, features_variance], axis=0)\n",
    "\n",
    "    # Normalize the features (optional)\n",
    "    features = (features - np.mean(features)) / np.std(features)  # Z-score normalization\n",
    "\n",
    "    return features\n",
    "\n",
    "def process_audio_file(file_path, n_fft=2048, hop_length=512, window_type='hann'):\n",
    "    \"\"\"\n",
    "    Process an audio file to extract STFT features.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the audio file\n",
    "        n_fft: FFT window size\n",
    "        hop_length: Hop length between frames\n",
    "        window_type: Type of window function to apply\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Extracted features\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    signal, sample_rate = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Compute features\n",
    "    features = compute_stfts_features(signal, sample_rate, n_fft, hop_length, window_type)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train1 data from .pkl files...\n",
      "Loading val1 data from .pkl files...\n",
      "Loading test1 data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "def load_stfts_features_from_directory(directory, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=None, dataset_type='train'):\n",
    "    \"\"\"\n",
    "    Load and compute stfts features from audio files in a directory, with improved accuracy.\n",
    "    Assumes 'Queen' and 'NonQueen' subdirectories are present.\n",
    "    \"\"\"\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    features_file = os.path.join(output_dir, f'stfts_features_{dataset_type}1.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'stfts_labels_{dataset_type}1.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
    "        print(f\"Loading {dataset_type}1 data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "\n",
    "        for label in ['Queen', 'NonQueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            for file in os.listdir(path):\n",
    "                file_path = os.path.join(path, file)\n",
    "                # Load audio file\n",
    "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "                # Compute stfts features\n",
    "                stfts_feature = compute_stfts_features(signal, sr, n_fft=n_fft, hop_length=hop_length, apply_log=True)\n",
    "\n",
    "                features.append(stfts_feature)\n",
    "                labels.append(label)\n",
    "\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
    "        if output_dir:\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"STFTs extraction time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "train_features_stfts, train_labels_stfts = load_stfts_features_from_directory(train_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='train')\n",
    "val_features_stfts, val_labels_stfts = load_stfts_features_from_directory(val_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='val')\n",
    "test_features_stfts, test_labels_stfts = load_stfts_features_from_directory(test_path, sample_rate=22050, n_fft=2048, hop_length=512, output_dir=output_dir, dataset_type='test')\n",
    "train_features_stfts = np.vstack((train_features_stfts, val_features_stfts))\n",
    "train_labels_stfts = np.hstack((train_labels_stfts, val_labels_stfts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_stfts = StandardScaler()\n",
    "train_features_stfts_scaled = scaler_stfts.fit_transform(train_features_stfts)\n",
    "test_features_stfts_scaled  = scaler_stfts.transform(test_features_stfts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFTs - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.00 seconds\n",
      "KNN (STFTs) - Test Accuracy: 93.62%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier_stfts = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                           metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "knn_classifier_stfts.fit(train_features_stfts, train_labels_stfts)\n",
    "test_pred_stfts_knn = knn_classifier_stfts.predict(test_features_stfts)\n",
    "\n",
    "test_accuracy_stfts_knn = accuracy_score(test_labels_stfts, test_pred_stfts_knn)\n",
    "print(f\"KNN (STFTs) - Test Accuracy: {test_accuracy_stfts_knn*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old 95.10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.00 seconds\n",
      "KNN (STFTs) - Test Accuracy: 92.58%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier_stfts = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                           metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "knn_classifier_stfts.fit(train_features_stfts_scaled, train_labels_stfts)\n",
    "test_pred_stfts_knn = knn_classifier_stfts.predict(test_features_stfts_scaled)\n",
    "\n",
    "test_accuracy_stfts_knn = accuracy_score(test_labels_stfts, test_pred_stfts_knn)\n",
    "print(f\"KNN (STFTs) - Test Accuracy: {test_accuracy_stfts_knn*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old 94.50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFTs - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 401.53 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 95.60%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=10, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_stfts_scaled, train_labels_stfts)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_stfts_scaled)\n",
    "scale_test_accuracy_stfts_svm = accuracy_score(test_labels_stfts, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_stfts_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFTs - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 41.69 seconds\n",
      "Logistic Regression (STFTs) - Test Accuracy: 88.95%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier_stfts = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', penalty= 'l2', C= 0.08858667904100823)\n",
    "lr_classifier_stfts.fit(train_features_stfts_scaled, train_labels_stfts)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_pred_stfts_lr = lr_classifier_stfts.predict(test_features_stfts_scaled)\n",
    "\n",
    "test_accuracy_stfts_lr = accuracy_score(test_labels_stfts, test_pred_stfts_lr)\n",
    "print(f\"Logistic Regression (STFTs) - Test Accuracy: {test_accuracy_stfts_lr*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFTs - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 184.78 seconds\n",
      "Random Forest (STFTs) - Test Accuracy: 93.30%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier_stfts = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
    "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "rf_classifier_stfts.fit(train_features_stfts, train_labels_stfts)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "val_pred_stfts_rf = rf_classifier_stfts.predict(val_features_stfts)\n",
    "test_pred_stfts_rf = rf_classifier_stfts.predict(test_features_stfts)\n",
    "\n",
    "test_accuracy_stfts_rf = accuracy_score(test_labels_stfts, test_pred_stfts_rf)\n",
    "print(f\"Random Forest (STFTs) - Test Accuracy: {test_accuracy_stfts_rf*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFTs - ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 211.25 seconds\n",
      "Extra Trees (STFTs) - Test Accuracy: 91.97%\n"
     ]
    }
   ],
   "source": [
    "start_time\n",
    "\n",
    "et_classifier_stfts = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "et_classifier_stfts.fit(train_features_stfts_scaled, train_labels_stfts)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_pred_stfts_et = et_classifier_stfts.predict(test_features_stfts_scaled)\n",
    "\n",
    "test_accuracy_stfts_et = accuracy_score(test_labels_stfts, test_pred_stfts_et)\n",
    "print(f\"Extra Trees (STFTs) - Test Accuracy: {test_accuracy_stfts_et*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cqt_features(signal_in, sample_rate, hop_length=512, fmin=None, \n",
    "                         n_bins=84, bins_per_octave=12, apply_log=True):\n",
    "    \"\"\"\n",
    "    Tính đặc trưng CQT của tín hiệu:\n",
    "      - Sử dụng librosa.cqt để tính ma trận CQT, lấy giá trị magnitude.\n",
    "      - (Tùy chọn) Áp dụng log scaling để giảm phạm vi giá trị.\n",
    "      - Trung bình theo trục thời gian (axis=1) để thu được vector đặc trưng có kích thước (n_bins,).\n",
    "      \n",
    "    Nếu fmin không được chỉ định, librosa sẽ tự động sử dụng fmin mặc định.\n",
    "    \"\"\"\n",
    "    cqt_matrix = np.abs(librosa.cqt(signal_in, sr=sample_rate, hop_length=hop_length,\n",
    "                                    fmin=fmin, n_bins=n_bins, bins_per_octave=bins_per_octave))\n",
    "    if apply_log:\n",
    "        cqt_matrix = np.log(cqt_matrix + 1e-8)\n",
    "    # Trung bình theo trục thời gian (tính trung bình các cột)\n",
    "    features = np.mean(cqt_matrix, axis=1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from .pkl files...\n",
      "Loading val data from .pkl files...\n",
      "Loading test data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "def load_cqt_features_from_directory(directory, sample_rate=22050, hop_length=512, \n",
    "                                     fmin=None, n_bins=84, bins_per_octave=12, output_dir=None, dataset_type='train'):\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    features_file = os.path.join(output_dir, f'cqt_features_{dataset_type}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'cqt_labels_{dataset_type}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        \n",
    "        for label in ['Queen', 'NonQueen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            for file in os.listdir(path):\n",
    "                file_path = os.path.join(path, file)\n",
    "                signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                \n",
    "                # Compute CQT features\n",
    "                cqt_feature = compute_cqt_features(signal, sr, hop_length=hop_length, \n",
    "                                                   fmin=fmin, n_bins=n_bins, bins_per_octave=bins_per_octave, \n",
    "                                                   apply_log=True)\n",
    "                \n",
    "                features.append(cqt_feature)\n",
    "                labels.append(label)\n",
    "\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
    "        if output_dir:\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"CQT extraction time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "train_features_cqt, train_labels_cqt = load_cqt_features_from_directory(train_path, sample_rate=22050,\n",
    "                                                                        hop_length=512, fmin=None, n_bins=84, bins_per_octave=12, \n",
    "                                                                        output_dir=output_dir, dataset_type='train')\n",
    "val_features_cqt, val_labels_cqt = load_cqt_features_from_directory(val_path, sample_rate=22050,\n",
    "                                                                    hop_length=512, fmin=None, n_bins=84, bins_per_octave=12, \n",
    "                                                                    output_dir=output_dir, dataset_type='val')\n",
    "test_features_cqt, test_labels_cqt = load_cqt_features_from_directory(test_path, sample_rate=22050,\n",
    "                                                                      hop_length=512, fmin=None, n_bins=84, bins_per_octave=12, \n",
    "                                                                      output_dir=output_dir, dataset_type='test')\n",
    "\n",
    "train_features_cqt = np.vstack((train_features_cqt, val_features_cqt))\n",
    "train_labels_cqt = np.hstack((train_labels_cqt, val_labels_cqt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_cqt = StandardScaler()\n",
    "train_features_cqt_scaled = scaler_cqt.fit_transform(train_features_cqt)\n",
    "test_features_cqt_scaled  = scaler_cqt.transform(test_features_cqt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CQT - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.01 seconds\n",
      "KNN (CQT) - Test Accuracy: 97.85%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier_cqt = KNeighborsClassifier(n_neighbors=1, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                      metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "knn_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_pred_cqt_knn = knn_classifier_cqt.predict(test_features_cqt_scaled)\n",
    "\n",
    "test_accuracy_cqt_knn = accuracy_score(test_labels_cqt, test_pred_cqt_knn)\n",
    "print(f\"KNN (CQT) - Test Accuracy: {test_accuracy_cqt_knn*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CQT - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 9.46 seconds\n",
      "SVM (CQT) - Test Accuracy: 97.12%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_classifier_cqt = SVC(C=100, kernel='rbf', gamma='auto', random_state=42)\n",
    "svm_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_pred_cqt_svm = svm_classifier_cqt.predict(test_features_cqt_scaled)\n",
    "\n",
    "test_accuracy_cqt_svm = accuracy_score(test_labels_cqt, test_pred_cqt_svm)\n",
    "print(f\"SVM (CQT) - Test Accuracy: {test_accuracy_cqt_svm*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CQT - LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.25 seconds\n",
      "Logistic Regression (CQT) - Test Accuracy: 83.55%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier_cqt =LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, \n",
    "                                      fit_intercept=True, intercept_scaling=1, \n",
    "                                      class_weight=None, random_state=None, solver='lbfgs', \n",
    "                                      max_iter=500, multi_class='deprecated', verbose=0, \n",
    "                                      warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "lr_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_pred_cqt_lr = lr_classifier_cqt.predict(test_features_cqt_scaled)\n",
    "\n",
    "test_accuracy_cqt_lr = accuracy_score(test_labels_cqt, test_pred_cqt_lr)\n",
    "print(f\"Logistic Regression (CQT) - Test Accuracy: {test_accuracy_cqt_lr*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CQT - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 33.02 seconds\n",
      "Random Forest (CQT) - Test Accuracy: 95.35%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier_cqt = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                       min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                       max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                       bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, \n",
    "                                       warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "rf_classifier_cqt.fit(train_features_cqt, train_labels_cqt)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_pred_cqt_rf = rf_classifier_cqt.predict(test_features_cqt)\n",
    "\n",
    "test_accuracy_cqt_rf = accuracy_score(test_labels_cqt, test_pred_cqt_rf)\n",
    "print(f\"Random Forest (CQT) - Test Accuracy: {test_accuracy_cqt_rf*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CQT - ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 34.56 seconds\n",
      "Extra Trees (CQT) - Test Accuracy: 95.97%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier_cqt = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "et_classifier_cqt.fit(train_features_cqt_scaled, train_labels_cqt)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_pred_cqt_et = et_classifier_cqt.predict(test_features_cqt_scaled)\n",
    "\n",
    "test_accuracy_cqt_et = accuracy_score(test_labels_cqt, test_pred_cqt_et)\n",
    "print(f\"Extra Trees (CQT) - Test Accuracy: {test_accuracy_cqt_et*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT + CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from .pkl files...\n",
      "Loading val data from .pkl files...\n",
      "Loading test data from .pkl files...\n"
     ]
    }
   ],
   "source": [
    "def pre_emphasis(signal_in, pre_emph=0.97):\n",
    "    \"\"\"\n",
    "    Áp dụng pre-emphasis để nhấn mạnh các tần số cao.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        pre_emph: Hệ số pre-emphasis, mặc định là 0.97\n",
    "        \n",
    "    Returns:\n",
    "        Tín hiệu sau khi áp dụng pre-emphasis\n",
    "    \"\"\"\n",
    "    return np.append(signal_in[0], signal_in[1:] - pre_emph * signal_in[:-1])\n",
    "\n",
    "def framing(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01):\n",
    "    \"\"\"\n",
    "    Chia tín hiệu thành các frame có kích thước và bước nhảy xác định.\n",
    "    \"\"\"\n",
    "    frame_length = int(round(frame_size * sample_rate))\n",
    "    frame_step = int(round(frame_stride * sample_rate))\n",
    "    signal_length = len(signal_in)\n",
    "    num_frames = int(np.ceil(np.abs(signal_length - frame_length) / frame_step)) + 1\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(signal_in, z)\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "    return frames\n",
    "\n",
    "def windowing(frames):\n",
    "    \"\"\"\n",
    "    Áp dụng cửa sổ Hamming cho mỗi frame.\n",
    "    \"\"\"\n",
    "    frame_length = frames.shape[1]\n",
    "    hamming = np.hamming(frame_length)\n",
    "    return frames * hamming\n",
    "\n",
    "def fft_frames(frames, NFFT=512):\n",
    "    \"\"\"\n",
    "    Tính FFT cho mỗi frame và lấy giá trị magnitude.\n",
    "    \"\"\"\n",
    "    return np.absolute(np.fft.rfft(frames, NFFT))\n",
    "\n",
    "def compute_fft_features(signal_in, sample_rate, frame_size=0.025, frame_stride=0.01, NFFT=512, apply_log=True):\n",
    "    \"\"\"\n",
    "    Tính toán đặc trưng FFT cho tín hiệu âm thanh:\n",
    "      - Pre-emphasis, Framing, Windowing.\n",
    "      - Tính FFT cho từng frame và lấy giá trị magnitude.\n",
    "      - Trung bình các frame để có vector đặc trưng ổn định.\n",
    "      - (Tùy chọn) Áp dụng log để giảm phạm vi giá trị.\n",
    "      \n",
    "    Trả về: vector đặc trưng có kích thước (NFFT/2+1,).\n",
    "    \"\"\"\n",
    "    emphasized_signal = pre_emphasis(signal_in)\n",
    "    frames = framing(emphasized_signal, sample_rate, frame_size, frame_stride)\n",
    "    windowed_frames = windowing(frames)\n",
    "    mag_frames = fft_frames(windowed_frames, NFFT)\n",
    "    fft_feature = np.mean(mag_frames, axis=0)  # Trung bình theo các frame\n",
    "    if apply_log:\n",
    "        fft_feature = np.log(fft_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
    "    return fft_feature\n",
    "\n",
    "def compute_cqt_features(signal_in, sample_rate, fmin=None, \n",
    "                         n_bins=84, bins_per_octave=12, apply_log=True):\n",
    "    \"\"\"\n",
    "    Tính đặc trưng CQT của tín hiệu:\n",
    "      - Sử dụng librosa.cqt để tính ma trận CQT, lấy giá trị magnitude.\n",
    "      - (Tùy chọn) Áp dụng log scaling để giảm phạm vi giá trị.\n",
    "      - Trung bình theo trục thời gian (axis=1) để thu được vector đặc trưng có kích thước (n_bins,).\n",
    "      \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        fmin: Tần số thấp nhất (Hz). Nếu None, librosa sẽ sử dụng mặc định\n",
    "        n_bins: Số lượng bin tần số\n",
    "        bins_per_octave: Số lượng bin cho mỗi quãng 8\n",
    "        apply_log: Áp dụng logarit cho đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng CQT có kích thước (n_bins,)\n",
    "    \"\"\"\n",
    "    cqt_matrix = np.abs(librosa.cqt(signal_in, sr=sample_rate,\n",
    "                                    fmin=fmin, n_bins=n_bins, bins_per_octave=bins_per_octave))\n",
    "    \n",
    "    # Trung bình theo trục thời gian (tính trung bình các cột)\n",
    "    cqt_feature = np.mean(cqt_matrix, axis=1)\n",
    "    \n",
    "    # Áp dụng logarithm (nếu cần)\n",
    "    if apply_log:\n",
    "        cqt_feature = np.log(cqt_feature + 1e-8)  # Thêm epsilon để tránh log(0)\n",
    "    \n",
    "    return cqt_feature\n",
    "\n",
    "def compute_features(signal_in, sample_rate, frame_size=0.025,\n",
    "                     NFFT=512,\n",
    "                     fmin=None, n_bins=84, bins_per_octave=12, apply_log=True):\n",
    "    \"\"\"\n",
    "    Tính toán và kết hợp đặc trưng FFT và CQT cho tín hiệu âm thanh.\n",
    "    \n",
    "    Args:\n",
    "        signal_in: Tín hiệu đầu vào\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        frame_size: Kích thước frame cho FFT (giây hoặc số mẫu nếu > 1)\n",
    "        NFFT: Số điểm FFT\n",
    "        fmin: Tần số thấp nhất (Hz) cho CQT\n",
    "        n_bins: Số lượng bin tần số cho CQT\n",
    "        bins_per_octave: Số lượng bin cho mỗi quãng 8 cho CQT\n",
    "        apply_log: Áp dụng logarit cho đặc trưng\n",
    "        \n",
    "    Returns:\n",
    "        Vector đặc trưng kết hợp FFT và CQT\n",
    "    \"\"\"\n",
    "    # Tính đặc trưng FFT\n",
    "    fft_feature = compute_fft_features(\n",
    "        signal_in, sample_rate, frame_size=frame_size,\n",
    "        NFFT=NFFT,\n",
    "        apply_log=apply_log\n",
    "    )\n",
    "    \n",
    "    # Tính đặc trưng CQT\n",
    "    cqt_feature = compute_cqt_features(\n",
    "        signal_in, sample_rate, fmin=fmin,\n",
    "        n_bins=n_bins, bins_per_octave=bins_per_octave,\n",
    "        apply_log=apply_log\n",
    "    )\n",
    "    \n",
    "    # Kết hợp hai đặc trưng\n",
    "    combined_feature = np.concatenate((fft_feature, cqt_feature))\n",
    "    \n",
    "    return combined_feature\n",
    "\n",
    "def load_features_from_directory(directory, sample_rate=22050, NFFT=512, \n",
    "                                 frame_size=0.025,\n",
    "                                 output_dir=None, \n",
    "                                 dataset_type='train',\n",
    "                                 fmin=None, n_bins=84, bins_per_octave=12):\n",
    "    \"\"\"\n",
    "    Duyệt qua các file âm thanh trong thư mục và tính đặc trưng kết hợp FFT và CQT cho mỗi file.\n",
    "    \n",
    "    Args:\n",
    "        directory: Thư mục chứa dữ liệu âm thanh\n",
    "        sample_rate: Tần số lấy mẫu\n",
    "        NFFT: Số điểm FFT\n",
    "        frame_size: Kích thước frame (giây hoặc số mẫu nếu > 1)\n",
    "        output_dir: Thư mục đầu ra để lưu đặc trưng\n",
    "        dataset_type: Loại tập dữ liệu ('train', 'test', 'val')\n",
    "        fmin: Tần số thấp nhất (Hz) cho CQT\n",
    "        n_bins: Số lượng bin tần số cho CQT\n",
    "        bins_per_octave: Số lượng bin cho mỗi quãng 8 cho CQT\n",
    "        \n",
    "    Returns:\n",
    "        features: Mảng đặc trưng kết hợp\n",
    "        labels: Nhãn tương ứng\n",
    "    \"\"\"\n",
    "    # Kiểm tra nếu file đã tồn tại, thì load lại\n",
    "    features_file = os.path.join(output_dir, f'combined_features2_{dataset_type}_nfft{NFFT}_bins{n_bins}.pkl')\n",
    "    labels_file = os.path.join(output_dir, f'combined_labels2_{dataset_type}_nfft{NFFT}_bins{n_bins}.pkl')\n",
    "    \n",
    "    if os.path.exists(features_file) and os.path.exists(labels_file):\n",
    "        print(f\"Loading {dataset_type} data from .pkl files...\")\n",
    "        features = joblib.load(features_file)\n",
    "        labels = joblib.load(labels_file)\n",
    "    else:\n",
    "        print(f\"Extracting {dataset_type} data...\")\n",
    "        start_time = time.time()\n",
    "        labels = []\n",
    "        features = []\n",
    "        \n",
    "        for label in ['NonQueen', 'Queen']:\n",
    "            path = os.path.join(directory, label)\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Warning: Path {path} does not exist. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            for file in os.listdir(path):\n",
    "                if not file.endswith(('.wav', '.mp3', '.flac', '.ogg')):\n",
    "                    continue\n",
    "                    \n",
    "                file_path = os.path.join(path, file)\n",
    "                try:\n",
    "                    signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                    \n",
    "                    # Tính toán đặc trưng kết hợp FFT và CQT\n",
    "                    combined_feature = compute_features(\n",
    "                        signal, sr, frame_size=frame_size,\n",
    "                        NFFT=NFFT,\n",
    "                        fmin=fmin, n_bins=n_bins, \n",
    "                        bins_per_octave=bins_per_octave\n",
    "                    )\n",
    "                    \n",
    "                    features.append(combined_feature)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        \n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Lưu dữ liệu vào file .pkl nếu chưa tồn tại\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            joblib.dump(features, features_file)\n",
    "            joblib.dump(labels, labels_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Feature extraction time: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Features shape: {features.shape}, Labels shape: {labels.shape}\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Trích xuất đặc trưng kết hợp cho tập dữ liệu\n",
    "train_features, train_labels = load_features_from_directory(\n",
    "    train_path, sample_rate=22050, NFFT=512, fmin=None, n_bins=96, bins_per_octave=12,\n",
    "    output_dir=output_dir, dataset_type='train'\n",
    ")\n",
    "\n",
    "val_features, val_labels = load_features_from_directory(\n",
    "    val_path, sample_rate=22050, NFFT=512, fmin=None, n_bins=96, bins_per_octave=12,\n",
    "    output_dir=output_dir, dataset_type='val'\n",
    ")\n",
    "\n",
    "test_features, test_labels = load_features_from_directory(\n",
    "    test_path, sample_rate=22050, NFFT=512, fmin=None, n_bins=96, bins_per_octave=12,\n",
    "    output_dir=output_dir, dataset_type='test'\n",
    ")\n",
    "\n",
    "train_features = np.vstack((train_features, val_features))\n",
    "train_labels = np.hstack((train_labels, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16076, 353)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled  = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.02 seconds\n",
      "KNN (FFT features) - Test Accuracy: 97.47%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_knn = knn_classifier.predict(test_features)\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels, test_accuracy_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.02 seconds\n",
      "KNN (FFT features) - Test Accuracy: 97.28%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_knn = knn_classifier.predict(test_features_scaled)\n",
    "print(f\"KNN (FFT features) - Test Accuracy: {accuracy_score(test_labels, test_accuracy_knn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 84.69 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 98.60%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "svm_rbf_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features)\n",
    "test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {test_accuracy_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 157.60 seconds\n",
      "Test Accuracy (SVM with RBF Kernel): 98.20%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "svm_rbf_classifier = SVC(C=100, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, \n",
    "                         probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "                         max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình SVM\n",
    "svm_rbf_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_svm_rbf = svm_rbf_classifier.predict(test_features_scaled)\n",
    "scale_test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm_rbf)\n",
    "print(f\"Test Accuracy (SVM with RBF Kernel): {scale_test_accuracy_svm * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 4.29 seconds\n",
      "Logistic Regression (FFT features) - Test Accuracy: 88.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinhg\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='lbfgs', max_iter=1500, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "lr_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_lr = lr_classifier.predict(test_features)\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels, test_accuracy_lr)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 95.42 seconds\n",
      "Logistic Regression (FFT features) - Test Accuracy: 88.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinhg\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, \n",
    "                                   class_weight=None, random_state=42, solver='saga', max_iter=1000, multi_class='deprecated', \n",
    "                                   verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "lr_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "scale_test_accuracy_lr = lr_classifier.predict(test_features_scaled)\n",
    "print(f\"Logistic Regression (FFT features) - Test Accuracy: {accuracy_score(test_labels, scale_test_accuracy_lr)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 44.20 seconds\n",
      "Random Forest (FFT features) - Test Accuracy: 95.55%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                       min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                                       max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                                       n_jobs=None, random_state=42, verbose=0, warm_start=False, class_weight=None, \n",
    "                                       ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "rf_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_accuracy_rf = rf_classifier.predict(test_features)\n",
    "print(f\"Random Forest (FFT features) - Test Accuracy: {accuracy_score(test_labels, test_accuracy_rf)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 187.79 seconds\n",
      "Test Accuracy (Extra Trees): 96.85%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "et_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features)\n",
    "test_accuracy_et = accuracy_score(test_labels, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {test_accuracy_et * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 186.33 seconds\n",
      "Test Accuracy (Extra Trees): 96.85%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=30, min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                                     bootstrap=False, oob_score=False, n_jobs=None, random_state=42, verbose=0, warm_start=False, \n",
    "                                     class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)\n",
    "\n",
    "# Huấn luyện mô hình Extra Trees với dữ liệu đã chuẩn hóa\n",
    "et_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá mô hình trên bộ testing\n",
    "test_predictions_et = et_classifier.predict(test_features_scaled)\n",
    "scale_test_accuracy_et = accuracy_score(test_labels, test_predictions_et)\n",
    "print(f\"Test Accuracy (Extra Trees): {scale_test_accuracy_et * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (Gradient Boosting): 16.04 seconds\n",
      "Test Accuracy (Gradient Boosting): 90.85%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, \n",
    "                            max_depth=3, min_samples_split=2,\n",
    "                            min_samples_leaf=1, subsample=1.0,\n",
    "                            max_features='sqrt', random_state=42)\n",
    "\n",
    "gb_classifier.fit(train_features_scaled, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time (Gradient Boosting): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "test_predictions_gb = gb_classifier.predict(test_features_scaled)\n",
    "test_accuracy_gb = accuracy_score(test_labels, test_predictions_gb)\n",
    "print(f\"Test Accuracy (Gradient Boosting): {test_accuracy_gb * 100:.2f}%\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinhg\\anaconda3\\envs\\AI\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:06:25] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (XGBoost): 30.55 seconds\n",
      "Test Accuracy (XGBoost): 97.32%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chuyển đổi các nhãn từ chuỗi sang số\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(train_labels)\n",
    "val_labels_enc = le.transform(val_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=30,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,    # Tắt cảnh báo về label encoder\n",
    "    eval_metric='logloss'       # Chỉ định hàm mất mát\n",
    ")\n",
    "xgb_classifier.fit(train_features, train_labels_enc)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time (XGBoost): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá trên bộ testing\n",
    "test_predictions_xgb = xgb_classifier.predict(test_features)\n",
    "test_accuracy_xgb = accuracy_score(test_labels_enc, test_predictions_xgb)\n",
    "print(f\"Test Accuracy (XGBoost): {test_accuracy_xgb * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8000, number of negative: 8076\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 90015\n",
      "[LightGBM] [Info] Number of data points in the train set: 16076, number of used features: 353\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497636 -> initscore=-0.009455\n",
      "[LightGBM] [Info] Start training from score -0.009455\n",
      "\n",
      "Training time (LightGBM): 2.35 seconds\n",
      "Test Accuracy (LightGBM): 97.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinhg\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lgbm_classifier = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=30,\n",
    "    random_state=42\n",
    ")\n",
    "lgbm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTraining time (LightGBM): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Đánh giá trên bộ testing\n",
    "test_predictions_lgbm = lgbm_classifier.predict(test_features)\n",
    "test_accuracy_lgbm = accuracy_score(test_labels, test_predictions_lgbm)\n",
    "print(f\"Test Accuracy (LightGBM): {test_accuracy_lgbm * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
